- index: 1
  input:
    - role: system
      content_type: text
      content: |-
        You are a routing agent that determines which specialized agent should handle a user's request.
        You operate in the context of a business intelligence tool that supports data modeling and data exploration, and more.
        Your input includes the user's previous messages and responses, as well as the user's latest message, which you are responsible for routing.
        Routing guidelines:
        - If the user's question relates to developing or permanently changing the data model, metrics, or dashboards, you should route to the developer.
        - If the user's question relates to exploring dashboards or retrieving specific business metrics, you should route to the analyst.
        - If the user asks a general question, you should route to the analyst.
        - If the user specifically requests an agent by name, you must route to that agent if it's available.
        You must answer with a single agent choice and no further explanation. Pick only from this list of available agents (description in parentheses):
        - analyst_agent (Agent that assists with data analysis tasks.)
        - developer_agent (Agent that assists with development tasks.)
    - role: user
      content_type: text
      content: This metrics view has an error. Can you fix it?
  response:
    - role: assistant
      content_type: text
      content: '{"agent":"developer_agent"}'
- index: 2
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
  response:
    - role: assistant
      content_type: tool_call
      id: call_mCyXL0CXIbjArpQkcuJQqVLH
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
- index: 3
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 4c1b33df638f40fa
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 4c1b33df638f40fa
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_secret_access_key","connector.s3.aws_access_key_id","connector.openai.api_key"],"resources":[],"parse_errors":[]}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_zxuBXF2FVQCXeO2G4L240Bex
      tool_name: list_files
      content: '{}'
- index: 4
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 4c1b33df638f40fa
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 4c1b33df638f40fa
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_secret_access_key","connector.s3.aws_access_key_id","connector.openai.api_key"],"resources":[],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 31b264fca12949c2
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 31b264fca12949c2
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/metrics/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.MetricsView","name":"mock_data","reconcile_error":"failed to validate dimension \"countr\": column \"countr\" not found in table","reconcile_status":"RECONCILE_STATUS_IDLE"},{"kind":"rill.runtime.v1.Explore","name":"mock_data","reconcile_error":"dependency error: resource \"mock_data\" (rill.runtime.v1.MetricsView) has an error","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/models/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.Model","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_CY3NRx1i0LxgjgsPsLOGtp39
      tool_name: read_file
      content: '{"path":"/metrics/mock_data.yaml"}'
- index: 5
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 4c1b33df638f40fa
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 4c1b33df638f40fa
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_secret_access_key","connector.s3.aws_access_key_id","connector.openai.api_key"],"resources":[],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 31b264fca12949c2
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 31b264fca12949c2
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/metrics/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.MetricsView","name":"mock_data","reconcile_error":"failed to validate dimension \"countr\": column \"countr\" not found in table","reconcile_status":"RECONCILE_STATUS_IDLE"},{"kind":"rill.runtime.v1.Explore","name":"mock_data","reconcile_error":"dependency error: resource \"mock_data\" (rill.runtime.v1.MetricsView) has an error","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/models/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.Model","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: dc995222fbb24168
      tool_name: read_file
      content: '{"path":"/metrics/mock_data.yaml"}'
    - role: tool
      content_type: tool_response
      id: dc995222fbb24168
      content: '{"Contents":"\ntype: metrics_view\nmodel: mock_data\ntimeseries: event_time\ndimensions:\n  - column: countr\nmeasures:\n  - name: total_value\n    expression: SUM(value)\n"}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_bowvfmy12vbENrs7GRlcssdC
      tool_name: show_table
      content: '{"table":"mock_data"}'
- index: 6
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 4c1b33df638f40fa
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 4c1b33df638f40fa
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_secret_access_key","connector.s3.aws_access_key_id","connector.openai.api_key"],"resources":[],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 31b264fca12949c2
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 31b264fca12949c2
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/metrics/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.MetricsView","name":"mock_data","reconcile_error":"failed to validate dimension \"countr\": column \"countr\" not found in table","reconcile_status":"RECONCILE_STATUS_IDLE"},{"kind":"rill.runtime.v1.Explore","name":"mock_data","reconcile_error":"dependency error: resource \"mock_data\" (rill.runtime.v1.MetricsView) has an error","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/models/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.Model","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: dc995222fbb24168
      tool_name: read_file
      content: '{"path":"/metrics/mock_data.yaml"}'
    - role: tool
      content_type: tool_response
      id: dc995222fbb24168
      content: '{"Contents":"\ntype: metrics_view\nmodel: mock_data\ntimeseries: event_time\ndimensions:\n  - column: countr\nmeasures:\n  - name: total_value\n    expression: SUM(value)\n"}'
    - role: assistant
      content_type: tool_call
      id: 0d409f7411ec4f62
      tool_name: show_table
      content: '{"table":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 0d409f7411ec4f62
      content: '{"name":"mock_data","is_view":false,"columns":[{"name":"event_time","type":"CODE_TIMESTAMP"},{"name":"country","type":"CODE_STRING"},{"name":"value","type":"CODE_INT32"}],"physical_size_bytes":536576}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_CrB3ijQgfORQpI162iyDFf0T
      tool_name: develop_file
      content: '{"path":"/metrics/mock_data.yaml","prompt":"Fix the metrics view error: dimension references column \"countr\" but the underlying table \"mock_data\" has columns event_time, country, value. Update the dimension to use column: country. Keep timeseries event_time and measure total_value = SUM(value). Ensure valid YAML for a metrics_view.","type":"metrics_view"}'
- index: 7
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: system
      content_type: text
      content: "# Instructions for developing a metrics view in Rill\n\n## Introduction\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database. They implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\n\nMetrics views are lightweight resources that only perform validation when reconciled. They are typically found downstream of connectors and models in the project's DAG. They power many user-facing features:\n\n- **Explore dashboards**: Interactive drill-down interfaces for data exploration\n- **Canvas dashboards**: Custom chart and table components\n- **Alerts**: Notifications when data meets certain criteria\n- **Reports**: Scheduled data exports and summaries\n- **Custom APIs**: Programmatic access to metrics\n\n## Core Concepts\n\n### Table source\n\nThe `model:` property specifies the underlying table that powers the metrics view. It can reference:\n\n1. **A model in the project**: Just use the model name (e.g., `model: events`)\n2. **An external table**: Specify the table name as it exists in the OLAP connector\n\n```yaml\n# Referencing a model in the project\nmodel: events\n\n# Referencing an external table (connector defaults to project's default OLAP)\nconnector: clickhouse  # Optional: specify if different from default\nmodel: my_external_table\n```\n\n**Note**: The `table:` property is a legacy alias for referencing external tables. Always prefer `model:` in new metrics views.\n\n### Timeseries\n\nThe `timeseries:` property identifies the timestamp column used for time-based filtering and line charts. This column must be a time/timestamp type in the underlying table.\n\n```yaml\ntimeseries: event_time\n```\n\nIf the timeseries column is not listed in `dimensions:`, Rill automatically adds it as a time dimension. You can optionally configure additional time-related settings:\n\n```yaml\ntimeseries: event_time\nsmallest_time_grain: hour      # Minimum granularity users can select\nfirst_day_of_week: 7           # Sunday (1=Monday, 7=Sunday)\nfirst_month_of_year: 4         # April (fiscal year starting in April)\n```\n\n### Dimensions\n\nDimensions are attributes you can group by or filter on. They are typically categorical (strings, enums) or temporal (dates, timestamps). Rill infers the dimension type from the underlying SQL data type:\n\n- **Categorical**: String, enum, boolean columns\n- **Time**: Timestamp, date, datetime columns\n- **Geospatial**: Geometry or geography columns\n\nDefine dimensions using either a direct column reference or a SQL expression:\n\n```yaml\ndimensions:\n  # Simple column reference\n  - name: country\n    column: country\n\n  # Computed expression\n  - name: device_category\n    expression: CASE WHEN device_type IN ('phone', 'tablet') THEN 'Mobile' ELSE 'Desktop' END\n\n  # With display name and description\n  - name: campaign_name\n    display_name: Campaign\n    description: Marketing campaign that drove the traffic\n    column: campaign_name\n```\n\n**Naming**: Each dimension needs a `name` (stable identifier used in APIs and references), which defaults to `column:` if provided. The `display_name:` is optional, and defaults to a humanized version of `name` if not specified.\n\n### Measures\n\nMeasures are aggregation expressions that compute numeric values when grouped by dimensions. They must use aggregate functions like `SUM()`, `COUNT()`, `AVG()`, `MIN()`, `MAX()`.\n\n```yaml\nmeasures:\n  - name: total_revenue\n    display_name: Total Revenue\n    expression: SUM(revenue)\n    description: Sum of all revenue in USD\n    format_preset: currency_usd\n\n  - name: unique_users\n    display_name: Unique Users\n    expression: COUNT(DISTINCT user_id)\n    format_preset: humanize\n\n  - name: conversion_rate\n    display_name: Conversion Rate\n    expression: SUM(conversions) / NULLIF(SUM(visits), 0)\n    format_preset: percentage\n    valid_percent_of_total: false  # Disable % of total for ratios\n```\n\n**Format presets**: Control how values are displayed:\n- `none`: Raw number\n- `humanize`: Round to K, M, B (e.g., 1.2M)\n- `currency_usd`: Dollar format with 2 decimals ($1,234.56)\n- `currency_eur`: Euro format\n- `percentage`: Multiply by 100 and add % sign\n- `interval_ms`: Convert milliseconds to human-readable duration\n\nFor custom formatting, use `format_d3` with a [d3-format](https://d3js.org/d3-format) string:\n\n```yaml\nformat_d3: \"$,.2f\"  # $1,234.56\nformat_d3: \".1%\"    # 12.3%\nformat_d3: \",.0f\"   # 1,235 (rounded, with thousands separator)\n```\n\n### Best practices for dimensions and measures\n\n**Naming conventions:**\n- Use `snake_case` for the `name` field (e.g., `total_revenue`, `unique_users`)\n- Only add `display_name` and `description` if they provide meaningful context beyond what `name` conveys (display names auto-humanize from the name by default)\n- Ensure measure names don't collide with column names in the underlying table\n\n**Getting started with measures:**\n- Start with a `COUNT(*)` measure as a baseline (e.g., `total_records` or `total_events`)\n- Add `SUM()` measures for numeric columns that represent quantities or values\n- Use `humanize` as the default format preset unless the data has a specific format requirement\n- Keep initial measures simple using only `COUNT`, `SUM`, `AVG`, `MIN`, `MAX` aggregations\n- Add more complex expressions (ratios, conditional aggregations) only when needed\n\n**Dimension selection:**\n- Include all categorical columns (strings, enums, booleans) that users might want to filter or group by\n- Include date/timestamp columns as dimensions for time-based analysis beyond the main timeseries\n- Start with 5-10 dimensions; add more based on user needs\n\n### Auto-generated explore\n\nWhen you create a metrics view, Rill automatically generates an explore dashboard with the same name, exposing all dimensions and measures. To customize the explore (you usually should not need to), add an `explore:` block:\n\n```yaml\nexplore:\n  display_name: Sales Dashboard\n  defaults:\n    time_range: P7D\n    measures:\n      - total_revenue\n      - order_count\n```\n\n**Legacy behavior**: Files with `version: 1` do NOT auto-generate an explore. Omit `version:` in new metrics views to get the auto-generated explore.\n\n## Full Example\n\nHere is a complete, annotated metrics view:\n\n```yaml\n# metrics/orders.yaml\ntype: metrics_view\n\n# Display metadata\ndisplay_name: Orders Analytics\ndescription: Analyze order performance by various dimensions\n\n# Data source - references the 'orders' model in the project\nmodel: orders\n\n# Time column for time-series charts and filtering\ntimeseries: order_date\nsmallest_time_grain: day\n\n# Dimensions for grouping and filtering\ndimensions:\n  - name: order_date\n    display_name: Order Date\n    column: order_date\n\n  - name: country\n    display_name: Country\n    column: shipping_country\n\n  - name: product_category\n    display_name: Product Category\n    column: category\n    description: High-level product grouping\n\n  - name: customer_segment\n    display_name: Customer Segment\n    expression: | \n      CASE\n        WHEN lifetime_value > 1000 THEN 'High Value'\n        WHEN lifetime_value > 100 THEN 'Medium Value'\n        ELSE 'Low Value'\n      END\n\n  - name: is_repeat_customer\n    display_name: Repeat Customer\n    expression: CASE WHEN order_number > 1 THEN 'Yes' ELSE 'No' END\n\n# Measures for aggregation\nmeasures:\n  - name: total_orders\n    display_name: Total Orders\n    expression: COUNT(*)\n    format_preset: humanize\n\n  - name: total_revenue\n    display_name: Total Revenue\n    expression: SUM(order_total)\n    format_preset: currency_usd\n    description: Gross revenue before refunds\n\n  - name: average_order_value\n    display_name: Avg Order Value\n    expression: SUM(order_total) / NULLIF(COUNT(*), 0)\n    format_preset: currency_usd\n    valid_percent_of_total: false\n\n  - name: unique_customers\n    display_name: Unique Customers\n    expression: COUNT(DISTINCT customer_id)\n    format_preset: humanize\n\n  - name: items_per_order\n    display_name: Items per Order\n    expression: SUM(item_count) / NULLIF(COUNT(*), 0)\n    format_d3: \",.1f\"\n    valid_percent_of_total: false\n```\n\n## Security Policies\n\nSecurity policies control who can access a metrics view and what data they can see. This is a powerful feature for multi-tenant dashboards and role-based access control.\n\n### Basic access control\n\nThe `access:` property controls whether users can view the metrics view at all:\n\n```yaml\nsecurity:\n  # Allow access for everyone\n  access: true\n\n  # Deny access for everyone (useful for draft dashboards)\n  access: false\n\n  # Conditional access based on user attributes\n  access: \"'{{ .user.admin }}' = 'true'\"\n```\n\nThe expression syntax should be a DuckDB expression, which will be evaluated in a sandbox without access to any tables.\n\n### Row-level security\n\nThe `row_filter:` property restricts which rows a user can see. It's a SQL expression that references user attributes via templating:\n\n```yaml\nsecurity:\n  access: true\n  row_filter: domain = '{{ .user.domain }}'\n```\n\nCommon user attributes:\n- `{{ .user.email }}`: User's email address\n- `{{ .user.domain }}`: Email domain (e.g., \"acme.com\")\n- `{{ .user.admin }}`: Boolean admin flag\n- Custom attributes configured in Rill Cloud\n\nThe row filter should use the SQL syntax of the metrics view's model, and can reference other tables in the model's connector.\n\n### Complex row filters\n\nUse logical operators for sophisticated access patterns:\n\n```yaml\nsecurity:\n  access: true\n  row_filter: >\n    {{ .user.admin }}\n    OR '{{ .user.domain }}' = 'acme.com'\n    {{ if hasKey .user \"tenant_id\" }}\n    OR tenant_id = '{{ .user.tenant_id }}'\n    {{ end }}\n```\n\n### Hiding dimensions and measures\n\nThe `exclude:` property conditionally hides specific dimensions or measures from certain users:\n\n```yaml\nsecurity:\n  access: true\n  exclude:\n    - if: \"NOT {{ .user.admin }}\"\n      names:\n        - cost_per_acquisition  # Hide sensitive cost data from non-admins\n        - internal_notes\n```\n\n## Advanced Features\n\n### Annotations\n\nAnnotations overlay contextual information (like events or milestones) on time-series charts:\n\n```yaml\nannotations:\n  - name: product_launches\n    model: product_launches  # Must have 'time' and 'description' columns\n    measures:\n      - total_revenue        # Only show on these measures\n\n  # Optional columns in annotation model:\n  # - time_end: For range annotations\n  # - grain: Show only at specific time grains (day, week, etc.)\n```\n\n### Unnest for array dimensions\n\nWhen a column contains arrays, use `unnest: true` to flatten it at query time:\n\n```yaml\ndimensions:\n  - name: tags\n    display_name: Tags\n    column: tags\n    unnest: true  # Allows filtering by individual array elements\n```\n\n### Cache configuration\n\nConfigure caching for slow metrics views that use external tables:\n\n```yaml\ncache:\n  enabled: true\n  key_ttl: 5m\n  key_sql: SELECT MAX(updated_at) FROM orders\n```\n\nYou should not add a `cache:` config when the metrics view references a model inside the project since Rill does automatic cache management in that case.\n\n## Dialect-Specific Notes\n\nSQL expressions in dimensions and measures use the underlying OLAP database's dialect.\n\n### DuckDB\n\nDuckDB is the default OLAP engine for local development.\n\n**Conditional aggregation with FILTER**:\n```yaml\n# DuckDB supports FILTER clause for conditional aggregation\nexpression: COUNT(*) FILTER (WHERE status = 'completed')\n```\n\n### ClickHouse\n\nClickHouse is recommended for production workloads with large datasets.\n\n**Conditional aggregation**:\n```yaml\n# ClickHouse uses IF or CASE inside aggregations\nexpression: countIf(status = 'completed')\nexpression: sumIf(revenue, status = 'completed')\n```\n\n**Date functions**:\n```yaml\nexpression: toYear(order_date)\nexpression: toStartOfMonth(order_date)\nexpression: toYYYYMMDD(order_date)\n```\n\n**Array functions**:\n```yaml\nexpression: arrayJoin(tags)  # Unnest arrays\n```\n\n### Druid\n\n**Approximate distinct counts**:\n```yaml\nexpression: APPROX_COUNT_DISTINCT_DS_HLL(user_id)\n```\n\n## JSON Schema\n\n```\nallOf:\n    - properties:\n        ai_instructions:\n            description: Extra instructions for [AI agents](/explore/mcp). Used to guide natural language question answering and routing.\n            type: string\n        annotations:\n            description: Used to define annotations that can be displayed on charts\n            items:\n                properties:\n                    connector:\n                        description: Refers to the connector to use for the annotation\n                        type: string\n                    database:\n                        description: Refers to the database to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n                        type: string\n                    database_schema:\n                        description: Refers to the schema to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n                        type: string\n                    measures:\n                        anyOf:\n                            - description: Simple field name as a string.\n                              type: string\n                            - description: List of field selectors, each can be a string or an object with detailed configuration.\n                              items:\n                                anyOf:\n                                    - description: Shorthand field selector, interpreted as the name.\n                                      type: string\n                                    - additionalProperties: false\n                                      description: Detailed field selector configuration with name and optional time grain.\n                                      properties:\n                                        name:\n                                            description: Name of the field to select.\n                                            type: string\n                                        time_grain:\n                                            description: Time grain for time-based dimensions.\n                                            enum:\n                                                - \"\"\n                                                - ms\n                                                - millisecond\n                                                - s\n                                                - second\n                                                - min\n                                                - minute\n                                                - hadditionalProperties: fal\n                                                - hour\n                                                - d\n                                                - day\n                                                - w\n                                                - week\n                                                - month\n                                                - q\n                                                - quarter\n                                                - \"y\"\n                                                - year\n                                            type: string\n                                      required:\n                                        - name\n                                      type: object\n                              type: array\n                        description: Specifies which measures to apply the annotation to. Applies to all measures if not specified\n                    model:\n                        description: Refers to the model powering the annotation (either table or model is required). The model must have 'time' and 'description' columns. Optional columns include 'time_end' for range annotations and 'grain' to specify when the annotation should appear based on dashboard grain level.\n                        type: string\n                    name:\n                        description: A stable identifier for the annotation. Defaults to model or table names when not specified\n                        type: string\n                    table:\n                        description: Refers to the table powering the annotation, should be used instead of model for annotations from external OLAP tables (either table or model is required)\n                        type: string\n                type: object\n            type: array\n        connector:\n            description: Refers to the connector type for the metrics view, see [OLAP engines](/developers/build/connectors/olap) for more information\n            type: string\n        database:\n            description: Refers to the database to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n            type: string\n        database_schema:\n            description: Refers to the schema to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n            type: string\n        description:\n            description: Refers to the description for the metrics view\n            type: string\n        dimensions:\n            description: Relates to exploring segments or dimensions of your data and filtering the dashboard\n            items:\n                anyOf:\n                    - required:\n                        - column\n                    - required:\n                        - expression\n                properties:\n                    column:\n                        description: a categorical column\n                        type: string\n                    description:\n                        description: a freeform text description of the dimension\n                        type: string\n                    display_name:\n                        description: a display name for your dimension\n                        type: string\n                    expression:\n                        description: a non-aggregate expression such as string_split(domain, '.'). One of column and expression is required but cannot have both at the same time\n                        type: string\n                    name:\n                        description: a stable identifier for the dimension\n                        type: string\n                    tags:\n                        description: optional list of tags for categorizing the dimension (defaults to empty)\n                        items:\n                            type: string\n                        type: array\n                    type:\n                        description: 'Dimension type: \"geo\" for geospatial dimensions, \"time\" for time dimensions or \"categorical\" for categorial dimensions. Default is undefined and the type will be inferred instead'\n                        type: string\n                    unnest:\n                        description: if true, allows multi-valued dimension to be unnested (such as lists) and filters will automatically switch to \"contains\" instead of exact match\n                        type: boolean\n                    uri:\n                        description: enable if your dimension is a clickable URL to enable single click navigation (boolean or valid SQL expression)\n                        type:\n                            - string\n                            - boolean\n                type: object\n            type: array\n        display_name:\n            description: Refers to the display name for the metrics view\n            type: string\n        explore:\n            $ref: '#/definitions/explore_properties'\n            description: Defines an optional inline explore view for the metrics view. If not specified a default explore will be emitted unless `skip` is set to true.\n            required:\n                - type\n        first_day_of_week:\n            description: Refers to the first day of the week for time grain aggregation (for example, Sunday instead of Monday). The valid values are 1 through 7 where Monday=1 and Sunday=7\n            type: integer\n        first_month_of_year:\n            description: Refers to the first month of the year for time grain aggregation. The valid values are 1 through 12 where January=1 and December=12\n            type: integer\n        measures:\n            description: Used to define the numeric aggregates of columns from your data model\n            items:\n                properties:\n                    description:\n                        description: a freeform text description of the measure\n                        type: string\n                    display_name:\n                        description: the display name of your measure.\n                        type: string\n                    expression:\n                        description: a combination of operators and functions for aggregations\n                        type: string\n                    format_d3:\n                        description: 'Controls the formatting of this measure using a [d3-format](https://d3js.org/d3-format) string. If an invalid format string is supplied, the measure will fall back to `format_preset: humanize`. A measure cannot have both `format_preset` and `format_d3`. If neither is provided, the humanize preset is used by default. Example: `format_d3: \".2f\"` formats using fixed-point notation with two decimal places. Example: `format_d3: \",.2r\"` formats using grouped thousands with two significant digits. (optional)'\n                        type: string\n                    format_d3_locale:\n                        description: |\n                            locale configuration passed through to D3, enabling changing the currency symbol among other things. For details, see the docs for D3's formatLocale.\n                              ```yaml\n                              format_d3: \"$,\"\n                              format_d3_locale:\n                                grouping: [3, 2]\n                                currency: [\"\", \"\"]\n                              ```\n                        properties:\n                            currency:\n                                description: the currency symbol\n                                type: array\n                            grouping:\n                                description: the grouping of the currency symbol\n                                type: array\n                        type: object\n                    format_preset:\n                        description: |\n                            Controls the formatting of this measure using a predefined preset. Measures cannot have both `format_preset` and `format_d3`. If neither is supplied, the measure will be formatted using the `humanize` preset by default.\n\n                              Available options:\n                              - `humanize`: Round numbers into thousands (K), millions(M), billions (B), etc.\n                              - `none`: Raw output.\n                              - `currency_usd`: Round to 2 decimal points with a dollar sign ($).\n                              - `currency_eur`: Round to 2 decimal points with a euro sign ().\n                              - `percentage`: Convert a rate into a percentage with a % sign.\n                              - `interval_ms`: Convert milliseconds into human-readable durations like hours (h), days (d), years (y), etc. (optional)\n                        type: string\n                    label:\n                        description: a label for your measure, deprecated use display_name\n                        type: string\n                    name:\n                        description: a stable identifier for the measure\n                        type: string\n                    per:\n                        $ref: '#/definitions/field_selectors_properties'\n                        description: for per dimensions\n                    requires:\n                        $ref: '#/definitions/field_selectors_properties'\n                        description: using an available measure or dimension in your metrics view to set a required parameter, cannot be used with simple measures. See [referencing measures](/developers/build/metrics-view/measures/referencing) for more information.\n                    tags:\n                        description: optional list of tags for categorizing the measure (defaults to empty)\n                        items:\n                            type: string\n                        type: array\n                    treat_nulls_as:\n                        description: used to configure what value to fill in for missing time buckets. This also works generally as COALESCING over non empty time buckets.\n                        type: string\n                    type:\n                        description: 'Measure calculation type: \"simple\" for basic aggregations, \"derived\" for calculations using other measures, or \"time_comparison\" for period-over-period analysis. Defaults to \"simple\" unless dependencies exist.'\n                        type: string\n                    valid_percent_of_total:\n                        description: a boolean indicating whether percent-of-total values should be rendered for this measure\n                        type: boolean\n                    window:\n                        anyOf:\n                            - description: 'Shorthand: `time` or `true` means time-partitioned, `all` means non-partitioned.'\n                              enum:\n                                - time\n                                - \"true\"\n                                - all\n                              type: string\n                            - additionalProperties: false\n                              description: Detailed window configuration for measure calculations, allowing control over partitioning, ordering, and frame definition.\n                              properties:\n                                frame:\n                                    description: Defines the window frame boundaries for calculations, specifying which rows are included in the window relative to the current row.\n                                    type: string\n                                order:\n                                    $ref: '#/definitions/field_selectors_properties'\n                                    description: Specifies the fields to order the window by, determining the sequence of rows within each partition.\n                                    type: string\n                                partition:\n                                    description: Controls whether the window is partitioned. When true, calculations are performed within each partition separately.\n                                    type: boolean\n                              type: object\n                        description: A measure window can be defined as a keyword string (e.g. 'time' or 'all') or an object with detailed window configuration. For more information, see the [window functions](/developers/build/metrics-view/measures/windows) documentation.\n                required:\n                    - name\n                    - display_name\n                    - expression\n                type: object\n            type: array\n        model:\n            description: Refers to the model powering the dashboard (either model or table is required)\n            type: string\n        parent:\n            description: Refers to the parent metrics view from which this metrics view is derived. If specified, this will inherit properties from the parent metrics view\n            type: string\n        parent_dimensions:\n            $ref: '#/definitions/field_selector_properties'\n            description: Optional field selectors for dimensions to inherit from the parent metrics view.\n        parent_measures:\n            $ref: '#/definitions/field_selector_properties'\n            description: Optional field selectors for measures to inherit from the parent metrics view.\n        security:\n            $ref: '#/definitions/security_policy_properties'\n            description: Defines a security policy for the dashboard\n        smallest_time_grain:\n            description: 'Refers to the smallest time granularity the user is allowed to view. The valid values are: millisecond, second, minute, hour, day, week, month, quarter, year'\n            type: string\n        table:\n            description: Refers to the table powering the dashboard, should be used instead of model for dashboards create from external OLAP tables (either table or model is required)\n            type: string\n        timeseries:\n            description: Refers to the timestamp column from your model that will underlie x-axis data in the line charts. If not specified, the line charts will not appear\n            type: string\n        type:\n            const: metrics_view\n            description: Refers to the resource type and must be `metrics_view`\n            type: string\n        version:\n            description: The version of the metrics view schema\n            type: string\n        watermark:\n            description: A SQL expression that tells us the max timestamp that the measures are considered valid for. Usually does not need to be overwritten\n            type: string\n      title: Properties\n      type: object\n    - $ref: '#/definitions/common_properties'\ndescription: In your Rill project directory, create a metrics view, `<metrics_view>.yaml`, file in the `metrics` directory. Rill will ingest the metric view definition next time you run `rill start`.\nid: metrics-views\ntitle: Metrics View YAML\ntype: object\n```"
    - role: user
      content_type: text
      content: |-
        You should develop a Rill project file based on the following task description: Fix the metrics view error: dimension references column "countr" but the underlying table "mock_data" has columns event_time, country, value. Update the dimension to use column: country. Keep timeseries event_time and measure total_value = SUM(value). Ensure valid YAML for a metrics_view.

        Here is some important context:
        - You should develop the file at path: /metrics/mock_data.yaml
        - The file should be of type: metrics_view
        - You are running as a sub-agent of a larger developer agent. Stay aligned on your specific task and avoid extra discovery. You should iterate until you have succeeded in your task, ideally such that there are no parse or reconcile errors. But if you can't avoid failure, it is acceptable to report the failure back to the parent agent.

        Here is some additional context that may or may not be relevant to your task:
        - The project's default OLAP connector is named duckdb (driver: duckdb).
  response:
    - role: assistant
      content_type: tool_call
      id: call_sPpUAzxvmjilIT00UZ85RQFl
      tool_name: write_file
      content: '{"contents":"type: metrics_view\n\n# Underlying table/model in the default OLAP connector (duckdb)\nmodel: mock_data\n\ntimeseries: event_time\n\ndimensions:\n  - name: country\n    column: country\n\nmeasures:\n  - name: total_value\n    display_name: Total Value\n    expression: SUM(value)\n    format_preset: humanize\n","path":"/metrics/mock_data.yaml"}'
- index: 8
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: system
      content_type: text
      content: "# Instructions for developing a metrics view in Rill\n\n## Introduction\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database. They implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\n\nMetrics views are lightweight resources that only perform validation when reconciled. They are typically found downstream of connectors and models in the project's DAG. They power many user-facing features:\n\n- **Explore dashboards**: Interactive drill-down interfaces for data exploration\n- **Canvas dashboards**: Custom chart and table components\n- **Alerts**: Notifications when data meets certain criteria\n- **Reports**: Scheduled data exports and summaries\n- **Custom APIs**: Programmatic access to metrics\n\n## Core Concepts\n\n### Table source\n\nThe `model:` property specifies the underlying table that powers the metrics view. It can reference:\n\n1. **A model in the project**: Just use the model name (e.g., `model: events`)\n2. **An external table**: Specify the table name as it exists in the OLAP connector\n\n```yaml\n# Referencing a model in the project\nmodel: events\n\n# Referencing an external table (connector defaults to project's default OLAP)\nconnector: clickhouse  # Optional: specify if different from default\nmodel: my_external_table\n```\n\n**Note**: The `table:` property is a legacy alias for referencing external tables. Always prefer `model:` in new metrics views.\n\n### Timeseries\n\nThe `timeseries:` property identifies the timestamp column used for time-based filtering and line charts. This column must be a time/timestamp type in the underlying table.\n\n```yaml\ntimeseries: event_time\n```\n\nIf the timeseries column is not listed in `dimensions:`, Rill automatically adds it as a time dimension. You can optionally configure additional time-related settings:\n\n```yaml\ntimeseries: event_time\nsmallest_time_grain: hour      # Minimum granularity users can select\nfirst_day_of_week: 7           # Sunday (1=Monday, 7=Sunday)\nfirst_month_of_year: 4         # April (fiscal year starting in April)\n```\n\n### Dimensions\n\nDimensions are attributes you can group by or filter on. They are typically categorical (strings, enums) or temporal (dates, timestamps). Rill infers the dimension type from the underlying SQL data type:\n\n- **Categorical**: String, enum, boolean columns\n- **Time**: Timestamp, date, datetime columns\n- **Geospatial**: Geometry or geography columns\n\nDefine dimensions using either a direct column reference or a SQL expression:\n\n```yaml\ndimensions:\n  # Simple column reference\n  - name: country\n    column: country\n\n  # Computed expression\n  - name: device_category\n    expression: CASE WHEN device_type IN ('phone', 'tablet') THEN 'Mobile' ELSE 'Desktop' END\n\n  # With display name and description\n  - name: campaign_name\n    display_name: Campaign\n    description: Marketing campaign that drove the traffic\n    column: campaign_name\n```\n\n**Naming**: Each dimension needs a `name` (stable identifier used in APIs and references), which defaults to `column:` if provided. The `display_name:` is optional, and defaults to a humanized version of `name` if not specified.\n\n### Measures\n\nMeasures are aggregation expressions that compute numeric values when grouped by dimensions. They must use aggregate functions like `SUM()`, `COUNT()`, `AVG()`, `MIN()`, `MAX()`.\n\n```yaml\nmeasures:\n  - name: total_revenue\n    display_name: Total Revenue\n    expression: SUM(revenue)\n    description: Sum of all revenue in USD\n    format_preset: currency_usd\n\n  - name: unique_users\n    display_name: Unique Users\n    expression: COUNT(DISTINCT user_id)\n    format_preset: humanize\n\n  - name: conversion_rate\n    display_name: Conversion Rate\n    expression: SUM(conversions) / NULLIF(SUM(visits), 0)\n    format_preset: percentage\n    valid_percent_of_total: false  # Disable % of total for ratios\n```\n\n**Format presets**: Control how values are displayed:\n- `none`: Raw number\n- `humanize`: Round to K, M, B (e.g., 1.2M)\n- `currency_usd`: Dollar format with 2 decimals ($1,234.56)\n- `currency_eur`: Euro format\n- `percentage`: Multiply by 100 and add % sign\n- `interval_ms`: Convert milliseconds to human-readable duration\n\nFor custom formatting, use `format_d3` with a [d3-format](https://d3js.org/d3-format) string:\n\n```yaml\nformat_d3: \"$,.2f\"  # $1,234.56\nformat_d3: \".1%\"    # 12.3%\nformat_d3: \",.0f\"   # 1,235 (rounded, with thousands separator)\n```\n\n### Best practices for dimensions and measures\n\n**Naming conventions:**\n- Use `snake_case` for the `name` field (e.g., `total_revenue`, `unique_users`)\n- Only add `display_name` and `description` if they provide meaningful context beyond what `name` conveys (display names auto-humanize from the name by default)\n- Ensure measure names don't collide with column names in the underlying table\n\n**Getting started with measures:**\n- Start with a `COUNT(*)` measure as a baseline (e.g., `total_records` or `total_events`)\n- Add `SUM()` measures for numeric columns that represent quantities or values\n- Use `humanize` as the default format preset unless the data has a specific format requirement\n- Keep initial measures simple using only `COUNT`, `SUM`, `AVG`, `MIN`, `MAX` aggregations\n- Add more complex expressions (ratios, conditional aggregations) only when needed\n\n**Dimension selection:**\n- Include all categorical columns (strings, enums, booleans) that users might want to filter or group by\n- Include date/timestamp columns as dimensions for time-based analysis beyond the main timeseries\n- Start with 5-10 dimensions; add more based on user needs\n\n### Auto-generated explore\n\nWhen you create a metrics view, Rill automatically generates an explore dashboard with the same name, exposing all dimensions and measures. To customize the explore (you usually should not need to), add an `explore:` block:\n\n```yaml\nexplore:\n  display_name: Sales Dashboard\n  defaults:\n    time_range: P7D\n    measures:\n      - total_revenue\n      - order_count\n```\n\n**Legacy behavior**: Files with `version: 1` do NOT auto-generate an explore. Omit `version:` in new metrics views to get the auto-generated explore.\n\n## Full Example\n\nHere is a complete, annotated metrics view:\n\n```yaml\n# metrics/orders.yaml\ntype: metrics_view\n\n# Display metadata\ndisplay_name: Orders Analytics\ndescription: Analyze order performance by various dimensions\n\n# Data source - references the 'orders' model in the project\nmodel: orders\n\n# Time column for time-series charts and filtering\ntimeseries: order_date\nsmallest_time_grain: day\n\n# Dimensions for grouping and filtering\ndimensions:\n  - name: order_date\n    display_name: Order Date\n    column: order_date\n\n  - name: country\n    display_name: Country\n    column: shipping_country\n\n  - name: product_category\n    display_name: Product Category\n    column: category\n    description: High-level product grouping\n\n  - name: customer_segment\n    display_name: Customer Segment\n    expression: | \n      CASE\n        WHEN lifetime_value > 1000 THEN 'High Value'\n        WHEN lifetime_value > 100 THEN 'Medium Value'\n        ELSE 'Low Value'\n      END\n\n  - name: is_repeat_customer\n    display_name: Repeat Customer\n    expression: CASE WHEN order_number > 1 THEN 'Yes' ELSE 'No' END\n\n# Measures for aggregation\nmeasures:\n  - name: total_orders\n    display_name: Total Orders\n    expression: COUNT(*)\n    format_preset: humanize\n\n  - name: total_revenue\n    display_name: Total Revenue\n    expression: SUM(order_total)\n    format_preset: currency_usd\n    description: Gross revenue before refunds\n\n  - name: average_order_value\n    display_name: Avg Order Value\n    expression: SUM(order_total) / NULLIF(COUNT(*), 0)\n    format_preset: currency_usd\n    valid_percent_of_total: false\n\n  - name: unique_customers\n    display_name: Unique Customers\n    expression: COUNT(DISTINCT customer_id)\n    format_preset: humanize\n\n  - name: items_per_order\n    display_name: Items per Order\n    expression: SUM(item_count) / NULLIF(COUNT(*), 0)\n    format_d3: \",.1f\"\n    valid_percent_of_total: false\n```\n\n## Security Policies\n\nSecurity policies control who can access a metrics view and what data they can see. This is a powerful feature for multi-tenant dashboards and role-based access control.\n\n### Basic access control\n\nThe `access:` property controls whether users can view the metrics view at all:\n\n```yaml\nsecurity:\n  # Allow access for everyone\n  access: true\n\n  # Deny access for everyone (useful for draft dashboards)\n  access: false\n\n  # Conditional access based on user attributes\n  access: \"'{{ .user.admin }}' = 'true'\"\n```\n\nThe expression syntax should be a DuckDB expression, which will be evaluated in a sandbox without access to any tables.\n\n### Row-level security\n\nThe `row_filter:` property restricts which rows a user can see. It's a SQL expression that references user attributes via templating:\n\n```yaml\nsecurity:\n  access: true\n  row_filter: domain = '{{ .user.domain }}'\n```\n\nCommon user attributes:\n- `{{ .user.email }}`: User's email address\n- `{{ .user.domain }}`: Email domain (e.g., \"acme.com\")\n- `{{ .user.admin }}`: Boolean admin flag\n- Custom attributes configured in Rill Cloud\n\nThe row filter should use the SQL syntax of the metrics view's model, and can reference other tables in the model's connector.\n\n### Complex row filters\n\nUse logical operators for sophisticated access patterns:\n\n```yaml\nsecurity:\n  access: true\n  row_filter: >\n    {{ .user.admin }}\n    OR '{{ .user.domain }}' = 'acme.com'\n    {{ if hasKey .user \"tenant_id\" }}\n    OR tenant_id = '{{ .user.tenant_id }}'\n    {{ end }}\n```\n\n### Hiding dimensions and measures\n\nThe `exclude:` property conditionally hides specific dimensions or measures from certain users:\n\n```yaml\nsecurity:\n  access: true\n  exclude:\n    - if: \"NOT {{ .user.admin }}\"\n      names:\n        - cost_per_acquisition  # Hide sensitive cost data from non-admins\n        - internal_notes\n```\n\n## Advanced Features\n\n### Annotations\n\nAnnotations overlay contextual information (like events or milestones) on time-series charts:\n\n```yaml\nannotations:\n  - name: product_launches\n    model: product_launches  # Must have 'time' and 'description' columns\n    measures:\n      - total_revenue        # Only show on these measures\n\n  # Optional columns in annotation model:\n  # - time_end: For range annotations\n  # - grain: Show only at specific time grains (day, week, etc.)\n```\n\n### Unnest for array dimensions\n\nWhen a column contains arrays, use `unnest: true` to flatten it at query time:\n\n```yaml\ndimensions:\n  - name: tags\n    display_name: Tags\n    column: tags\n    unnest: true  # Allows filtering by individual array elements\n```\n\n### Cache configuration\n\nConfigure caching for slow metrics views that use external tables:\n\n```yaml\ncache:\n  enabled: true\n  key_ttl: 5m\n  key_sql: SELECT MAX(updated_at) FROM orders\n```\n\nYou should not add a `cache:` config when the metrics view references a model inside the project since Rill does automatic cache management in that case.\n\n## Dialect-Specific Notes\n\nSQL expressions in dimensions and measures use the underlying OLAP database's dialect.\n\n### DuckDB\n\nDuckDB is the default OLAP engine for local development.\n\n**Conditional aggregation with FILTER**:\n```yaml\n# DuckDB supports FILTER clause for conditional aggregation\nexpression: COUNT(*) FILTER (WHERE status = 'completed')\n```\n\n### ClickHouse\n\nClickHouse is recommended for production workloads with large datasets.\n\n**Conditional aggregation**:\n```yaml\n# ClickHouse uses IF or CASE inside aggregations\nexpression: countIf(status = 'completed')\nexpression: sumIf(revenue, status = 'completed')\n```\n\n**Date functions**:\n```yaml\nexpression: toYear(order_date)\nexpression: toStartOfMonth(order_date)\nexpression: toYYYYMMDD(order_date)\n```\n\n**Array functions**:\n```yaml\nexpression: arrayJoin(tags)  # Unnest arrays\n```\n\n### Druid\n\n**Approximate distinct counts**:\n```yaml\nexpression: APPROX_COUNT_DISTINCT_DS_HLL(user_id)\n```\n\n## JSON Schema\n\n```\nallOf:\n    - properties:\n        ai_instructions:\n            description: Extra instructions for [AI agents](/explore/mcp). Used to guide natural language question answering and routing.\n            type: string\n        annotations:\n            description: Used to define annotations that can be displayed on charts\n            items:\n                properties:\n                    connector:\n                        description: Refers to the connector to use for the annotation\n                        type: string\n                    database:\n                        description: Refers to the database to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n                        type: string\n                    database_schema:\n                        description: Refers to the schema to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n                        type: string\n                    measures:\n                        anyOf:\n                            - description: Simple field name as a string.\n                              type: string\n                            - description: List of field selectors, each can be a string or an object with detailed configuration.\n                              items:\n                                anyOf:\n                                    - description: Shorthand field selector, interpreted as the name.\n                                      type: string\n                                    - additionalProperties: false\n                                      description: Detailed field selector configuration with name and optional time grain.\n                                      properties:\n                                        name:\n                                            description: Name of the field to select.\n                                            type: string\n                                        time_grain:\n                                            description: Time grain for time-based dimensions.\n                                            enum:\n                                                - \"\"\n                                                - ms\n                                                - millisecond\n                                                - s\n                                                - second\n                                                - min\n                                                - minute\n                                                - hadditionalProperties: fal\n                                                - hour\n                                                - d\n                                                - day\n                                                - w\n                                                - week\n                                                - month\n                                                - q\n                                                - quarter\n                                                - \"y\"\n                                                - year\n                                            type: string\n                                      required:\n                                        - name\n                                      type: object\n                              type: array\n                        description: Specifies which measures to apply the annotation to. Applies to all measures if not specified\n                    model:\n                        description: Refers to the model powering the annotation (either table or model is required). The model must have 'time' and 'description' columns. Optional columns include 'time_end' for range annotations and 'grain' to specify when the annotation should appear based on dashboard grain level.\n                        type: string\n                    name:\n                        description: A stable identifier for the annotation. Defaults to model or table names when not specified\n                        type: string\n                    table:\n                        description: Refers to the table powering the annotation, should be used instead of model for annotations from external OLAP tables (either table or model is required)\n                        type: string\n                type: object\n            type: array\n        connector:\n            description: Refers to the connector type for the metrics view, see [OLAP engines](/developers/build/connectors/olap) for more information\n            type: string\n        database:\n            description: Refers to the database to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n            type: string\n        database_schema:\n            description: Refers to the schema to use in the OLAP engine (to be used in conjunction with table). Otherwise, will use the default database or schema if not specified\n            type: string\n        description:\n            description: Refers to the description for the metrics view\n            type: string\n        dimensions:\n            description: Relates to exploring segments or dimensions of your data and filtering the dashboard\n            items:\n                anyOf:\n                    - required:\n                        - column\n                    - required:\n                        - expression\n                properties:\n                    column:\n                        description: a categorical column\n                        type: string\n                    description:\n                        description: a freeform text description of the dimension\n                        type: string\n                    display_name:\n                        description: a display name for your dimension\n                        type: string\n                    expression:\n                        description: a non-aggregate expression such as string_split(domain, '.'). One of column and expression is required but cannot have both at the same time\n                        type: string\n                    name:\n                        description: a stable identifier for the dimension\n                        type: string\n                    tags:\n                        description: optional list of tags for categorizing the dimension (defaults to empty)\n                        items:\n                            type: string\n                        type: array\n                    type:\n                        description: 'Dimension type: \"geo\" for geospatial dimensions, \"time\" for time dimensions or \"categorical\" for categorial dimensions. Default is undefined and the type will be inferred instead'\n                        type: string\n                    unnest:\n                        description: if true, allows multi-valued dimension to be unnested (such as lists) and filters will automatically switch to \"contains\" instead of exact match\n                        type: boolean\n                    uri:\n                        description: enable if your dimension is a clickable URL to enable single click navigation (boolean or valid SQL expression)\n                        type:\n                            - string\n                            - boolean\n                type: object\n            type: array\n        display_name:\n            description: Refers to the display name for the metrics view\n            type: string\n        explore:\n            $ref: '#/definitions/explore_properties'\n            description: Defines an optional inline explore view for the metrics view. If not specified a default explore will be emitted unless `skip` is set to true.\n            required:\n                - type\n        first_day_of_week:\n            description: Refers to the first day of the week for time grain aggregation (for example, Sunday instead of Monday). The valid values are 1 through 7 where Monday=1 and Sunday=7\n            type: integer\n        first_month_of_year:\n            description: Refers to the first month of the year for time grain aggregation. The valid values are 1 through 12 where January=1 and December=12\n            type: integer\n        measures:\n            description: Used to define the numeric aggregates of columns from your data model\n            items:\n                properties:\n                    description:\n                        description: a freeform text description of the measure\n                        type: string\n                    display_name:\n                        description: the display name of your measure.\n                        type: string\n                    expression:\n                        description: a combination of operators and functions for aggregations\n                        type: string\n                    format_d3:\n                        description: 'Controls the formatting of this measure using a [d3-format](https://d3js.org/d3-format) string. If an invalid format string is supplied, the measure will fall back to `format_preset: humanize`. A measure cannot have both `format_preset` and `format_d3`. If neither is provided, the humanize preset is used by default. Example: `format_d3: \".2f\"` formats using fixed-point notation with two decimal places. Example: `format_d3: \",.2r\"` formats using grouped thousands with two significant digits. (optional)'\n                        type: string\n                    format_d3_locale:\n                        description: |\n                            locale configuration passed through to D3, enabling changing the currency symbol among other things. For details, see the docs for D3's formatLocale.\n                              ```yaml\n                              format_d3: \"$,\"\n                              format_d3_locale:\n                                grouping: [3, 2]\n                                currency: [\"\", \"\"]\n                              ```\n                        properties:\n                            currency:\n                                description: the currency symbol\n                                type: array\n                            grouping:\n                                description: the grouping of the currency symbol\n                                type: array\n                        type: object\n                    format_preset:\n                        description: |\n                            Controls the formatting of this measure using a predefined preset. Measures cannot have both `format_preset` and `format_d3`. If neither is supplied, the measure will be formatted using the `humanize` preset by default.\n\n                              Available options:\n                              - `humanize`: Round numbers into thousands (K), millions(M), billions (B), etc.\n                              - `none`: Raw output.\n                              - `currency_usd`: Round to 2 decimal points with a dollar sign ($).\n                              - `currency_eur`: Round to 2 decimal points with a euro sign ().\n                              - `percentage`: Convert a rate into a percentage with a % sign.\n                              - `interval_ms`: Convert milliseconds into human-readable durations like hours (h), days (d), years (y), etc. (optional)\n                        type: string\n                    label:\n                        description: a label for your measure, deprecated use display_name\n                        type: string\n                    name:\n                        description: a stable identifier for the measure\n                        type: string\n                    per:\n                        $ref: '#/definitions/field_selectors_properties'\n                        description: for per dimensions\n                    requires:\n                        $ref: '#/definitions/field_selectors_properties'\n                        description: using an available measure or dimension in your metrics view to set a required parameter, cannot be used with simple measures. See [referencing measures](/developers/build/metrics-view/measures/referencing) for more information.\n                    tags:\n                        description: optional list of tags for categorizing the measure (defaults to empty)\n                        items:\n                            type: string\n                        type: array\n                    treat_nulls_as:\n                        description: used to configure what value to fill in for missing time buckets. This also works generally as COALESCING over non empty time buckets.\n                        type: string\n                    type:\n                        description: 'Measure calculation type: \"simple\" for basic aggregations, \"derived\" for calculations using other measures, or \"time_comparison\" for period-over-period analysis. Defaults to \"simple\" unless dependencies exist.'\n                        type: string\n                    valid_percent_of_total:\n                        description: a boolean indicating whether percent-of-total values should be rendered for this measure\n                        type: boolean\n                    window:\n                        anyOf:\n                            - description: 'Shorthand: `time` or `true` means time-partitioned, `all` means non-partitioned.'\n                              enum:\n                                - time\n                                - \"true\"\n                                - all\n                              type: string\n                            - additionalProperties: false\n                              description: Detailed window configuration for measure calculations, allowing control over partitioning, ordering, and frame definition.\n                              properties:\n                                frame:\n                                    description: Defines the window frame boundaries for calculations, specifying which rows are included in the window relative to the current row.\n                                    type: string\n                                order:\n                                    $ref: '#/definitions/field_selectors_properties'\n                                    description: Specifies the fields to order the window by, determining the sequence of rows within each partition.\n                                    type: string\n                                partition:\n                                    description: Controls whether the window is partitioned. When true, calculations are performed within each partition separately.\n                                    type: boolean\n                              type: object\n                        description: A measure window can be defined as a keyword string (e.g. 'time' or 'all') or an object with detailed window configuration. For more information, see the [window functions](/developers/build/metrics-view/measures/windows) documentation.\n                required:\n                    - name\n                    - display_name\n                    - expression\n                type: object\n            type: array\n        model:\n            description: Refers to the model powering the dashboard (either model or table is required)\n            type: string\n        parent:\n            description: Refers to the parent metrics view from which this metrics view is derived. If specified, this will inherit properties from the parent metrics view\n            type: string\n        parent_dimensions:\n            $ref: '#/definitions/field_selector_properties'\n            description: Optional field selectors for dimensions to inherit from the parent metrics view.\n        parent_measures:\n            $ref: '#/definitions/field_selector_properties'\n            description: Optional field selectors for measures to inherit from the parent metrics view.\n        security:\n            $ref: '#/definitions/security_policy_properties'\n            description: Defines a security policy for the dashboard\n        smallest_time_grain:\n            description: 'Refers to the smallest time granularity the user is allowed to view. The valid values are: millisecond, second, minute, hour, day, week, month, quarter, year'\n            type: string\n        table:\n            description: Refers to the table powering the dashboard, should be used instead of model for dashboards create from external OLAP tables (either table or model is required)\n            type: string\n        timeseries:\n            description: Refers to the timestamp column from your model that will underlie x-axis data in the line charts. If not specified, the line charts will not appear\n            type: string\n        type:\n            const: metrics_view\n            description: Refers to the resource type and must be `metrics_view`\n            type: string\n        version:\n            description: The version of the metrics view schema\n            type: string\n        watermark:\n            description: A SQL expression that tells us the max timestamp that the measures are considered valid for. Usually does not need to be overwritten\n            type: string\n      title: Properties\n      type: object\n    - $ref: '#/definitions/common_properties'\ndescription: In your Rill project directory, create a metrics view, `<metrics_view>.yaml`, file in the `metrics` directory. Rill will ingest the metric view definition next time you run `rill start`.\nid: metrics-views\ntitle: Metrics View YAML\ntype: object\n```"
    - role: user
      content_type: text
      content: |-
        You should develop a Rill project file based on the following task description: Fix the metrics view error: dimension references column "countr" but the underlying table "mock_data" has columns event_time, country, value. Update the dimension to use column: country. Keep timeseries event_time and measure total_value = SUM(value). Ensure valid YAML for a metrics_view.

        Here is some important context:
        - You should develop the file at path: /metrics/mock_data.yaml
        - The file should be of type: metrics_view
        - You are running as a sub-agent of a larger developer agent. Stay aligned on your specific task and avoid extra discovery. You should iterate until you have succeeded in your task, ideally such that there are no parse or reconcile errors. But if you can't avoid failure, it is acceptable to report the failure back to the parent agent.

        Here is some additional context that may or may not be relevant to your task:
        - The project's default OLAP connector is named duckdb (driver: duckdb).
    - role: assistant
      content_type: tool_call
      id: 88f33f5d64674e02
      tool_name: write_file
      content: '{"contents":"type: metrics_view\n\n# Underlying table/model in the default OLAP connector (duckdb)\nmodel: mock_data\n\ntimeseries: event_time\n\ndimensions:\n  - name: country\n    column: country\n\nmeasures:\n  - name: total_value\n    display_name: Total Value\n    expression: SUM(value)\n    format_preset: humanize\n","path":"/metrics/mock_data.yaml"}'
    - role: tool
      content_type: tool_response
      id: 88f33f5d64674e02
      content: '{"diff":"--- /metrics/mock_data.yaml\n+++ /metrics/mock_data.yaml\n@@ -1,10 +1,17 @@\n+type: metrics_view\n \n-type: metrics_view\n+# Underlying table/model in the default OLAP connector (duckdb)\n model: mock_data\n+\n timeseries: event_time\n+\n dimensions:\n-  - column: countr\n+  - name: country\n+    column: country\n+\n measures:\n   - name: total_value\n+    display_name: Total Value\n     expression: SUM(value)\n+    format_preset: humanize\n \n","resources":[{"kind":"rill.runtime.v1.MetricsView","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"},{"kind":"rill.runtime.v1.Explore","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]}'
  response:
    - role: assistant
      content_type: text
      content: 'Updated `/metrics/mock_data.yaml` to fix the dimension error by changing the dimension to reference `column: country` (instead of the misspelled `countr`). Kept `timeseries: event_time` and the measure `total_value = SUM(value)`. The file is valid `metrics_view` YAML and reconciled successfully (no parse/reconcile errors).'
- index: 9
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 4c1b33df638f40fa
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 4c1b33df638f40fa
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_secret_access_key","connector.s3.aws_access_key_id","connector.openai.api_key"],"resources":[],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 31b264fca12949c2
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 31b264fca12949c2
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/metrics/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.MetricsView","name":"mock_data","reconcile_error":"failed to validate dimension \"countr\": column \"countr\" not found in table","reconcile_status":"RECONCILE_STATUS_IDLE"},{"kind":"rill.runtime.v1.Explore","name":"mock_data","reconcile_error":"dependency error: resource \"mock_data\" (rill.runtime.v1.MetricsView) has an error","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/models/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.Model","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: dc995222fbb24168
      tool_name: read_file
      content: '{"path":"/metrics/mock_data.yaml"}'
    - role: tool
      content_type: tool_response
      id: dc995222fbb24168
      content: '{"Contents":"\ntype: metrics_view\nmodel: mock_data\ntimeseries: event_time\ndimensions:\n  - column: countr\nmeasures:\n  - name: total_value\n    expression: SUM(value)\n"}'
    - role: assistant
      content_type: tool_call
      id: 0d409f7411ec4f62
      tool_name: show_table
      content: '{"table":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 0d409f7411ec4f62
      content: '{"name":"mock_data","is_view":false,"columns":[{"name":"event_time","type":"CODE_TIMESTAMP"},{"name":"country","type":"CODE_STRING"},{"name":"value","type":"CODE_INT32"}],"physical_size_bytes":536576}'
    - role: assistant
      content_type: tool_call
      id: 81ba6f3eb1a4414f
      tool_name: develop_file
      content: '{"path":"/metrics/mock_data.yaml","prompt":"Fix the metrics view error: dimension references column \"countr\" but the underlying table \"mock_data\" has columns event_time, country, value. Update the dimension to use column: country. Keep timeseries event_time and measure total_value = SUM(value). Ensure valid YAML for a metrics_view.","type":"metrics_view"}'
    - role: tool
      content_type: tool_response
      id: 81ba6f3eb1a4414f
      content: '{"response":"Updated `/metrics/mock_data.yaml` to fix the dimension error by changing the dimension to reference `column: country` (instead of the misspelled `countr`). Kept `timeseries: event_time` and the measure `total_value = SUM(value)`. The file is valid `metrics_view` YAML and reconciled successfully (no parse/reconcile errors)."}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_lKUHPqwheQkCH22iMHjKDJzk
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
- index: 10
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring object stores; load files into models using SQL before querying them\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n"
    - role: user
      content_type: text
      content: |-
        The user is currently viewing/editing the file: /metrics/mock_data.yaml
        Their request may or may not relate to this file.






        This may not relate to the user's task, but for context, the project's default OLAP connector is named duckdb (driver: duckdb).
         The default OLAP is in readwrite mode, so you can use it in models if you want.


        Task: This metrics view has an error. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 4c1b33df638f40fa
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 4c1b33df638f40fa
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_secret_access_key","connector.s3.aws_access_key_id","connector.openai.api_key"],"resources":[],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 31b264fca12949c2
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 31b264fca12949c2
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/metrics/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.MetricsView","name":"mock_data","reconcile_error":"failed to validate dimension \"countr\": column \"countr\" not found in table","reconcile_status":"RECONCILE_STATUS_IDLE"},{"kind":"rill.runtime.v1.Explore","name":"mock_data","reconcile_error":"dependency error: resource \"mock_data\" (rill.runtime.v1.MetricsView) has an error","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/models/mock_data.yaml","resources":[{"kind":"rill.runtime.v1.Model","name":"mock_data","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: dc995222fbb24168
      tool_name: read_file
      content: '{"path":"/metrics/mock_data.yaml"}'
    - role: tool
      content_type: tool_response
      id: dc995222fbb24168
      content: '{"Contents":"\ntype: metrics_view\nmodel: mock_data\ntimeseries: event_time\ndimensions:\n  - column: countr\nmeasures:\n  - name: total_value\n    expression: SUM(value)\n"}'
    - role: assistant
      content_type: tool_call
      id: 0d409f7411ec4f62
      tool_name: show_table
      content: '{"table":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 0d409f7411ec4f62
      content: '{"name":"mock_data","is_view":false,"columns":[{"name":"event_time","type":"CODE_TIMESTAMP"},{"name":"country","type":"CODE_STRING"},{"name":"value","type":"CODE_INT32"}],"physical_size_bytes":536576}'
    - role: assistant
      content_type: tool_call
      id: 81ba6f3eb1a4414f
      tool_name: develop_file
      content: '{"path":"/metrics/mock_data.yaml","prompt":"Fix the metrics view error: dimension references column \"countr\" but the underlying table \"mock_data\" has columns event_time, country, value. Update the dimension to use column: country. Keep timeseries event_time and measure total_value = SUM(value). Ensure valid YAML for a metrics_view.","type":"metrics_view"}'
    - role: tool
      content_type: tool_response
      id: 81ba6f3eb1a4414f
      content: '{"response":"Updated `/metrics/mock_data.yaml` to fix the dimension error by changing the dimension to reference `column: country` (instead of the misspelled `countr`). Kept `timeseries: event_time` and the measure `total_value = SUM(value)`. The file is valid `metrics_view` YAML and reconciled successfully (no parse/reconcile errors)."}'
    - role: assistant
      content_type: tool_call
      id: 514a0c43af6e4689
      tool_name: project_status
      content: '{"kind":"metrics_view","name":"mock_data"}'
    - role: tool
      content_type: tool_response
      id: 514a0c43af6e4689
      content: '{"default_olap_connector":"duckdb","variable_names":["connector.s3.aws_access_key_id","connector.openai.api_key","connector.s3.aws_secret_access_key"],"resources":[],"parse_errors":[]}'
  response:
    - role: assistant
      content_type: text
      content: |-
        The error was caused by a misspelled dimension column in `/metrics/mock_data.yaml`: it referenced `countr`, but the underlying `mock_data` table has `country`.

        I fixed it by updating the dimension to use `column: country`. The metrics view should now validate and the dependent Explore should work again.

        Updated file:

        ```yaml
        type: metrics_view
        model: mock_data
        timeseries: event_time
        dimensions:
          - column: country
        measures:
          - name: total_value
            expression: SUM(value)
        ```
