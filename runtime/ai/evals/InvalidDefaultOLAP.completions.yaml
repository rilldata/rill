- index: 1
  input:
    - role: system
      content_type: text
      content: |-
        You are a routing agent that determines which specialized agent should handle a user's request.
        You operate in the context of a business intelligence tool that supports data modeling and data exploration, and more.
        Your input includes the user's previous messages and responses, as well as the user's latest message, which you are responsible for routing.
        Routing guidelines:
        - If the user's question relates to developing or permanently changing the data model, metrics, or dashboards, you should route to the developer.
        - If the user's question relates to exploring dashboards or retrieving specific business metrics, you should route to the analyst.
        - If the user asks a general question, you should route to the analyst.
        - If the user specifically requests an agent by name, you must route to that agent if it's available.
        You must answer with a single agent choice and no further explanation. Pick only from this list of available agents (description in parentheses):
        - analyst_agent (Agent that assists with data analysis tasks.)
        - developer_agent (Agent that assists with development tasks.)
    - role: user
      content_type: text
      content: The default OLAP connector is misconfigured. Can you fix it?
  response:
    - role: assistant
      content_type: text
      content: '{"agent":"developer_agent"}'
- index: 2
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: user
      content_type: text
      content: |-
        For context, here are some details about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
        Note that you can only use it in model resources if it is not readonly.

        Call "navigate" tool for the main file created/edited in the conversation. Use kind "file" and pass the written file path.
        Prefer dashboard or metrics view files over other files.

        Task: The default OLAP connector is misconfigured. Can you fix it?
  response:
    - role: assistant
      content_type: tool_call
      id: call_lRerPONOIiGXiIRuqzkjf6WZ
      tool_name: project_status
      content: '{}'
    - role: assistant
      content_type: tool_call
      id: call_LLEjtDsM2FVmxE5bkaGhO0VU
      tool_name: list_files
      content: '{}'
- index: 3
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: user
      content_type: text
      content: |-
        For context, here are some details about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
        Note that you can only use it in model resources if it is not readonly.

        Call "navigate" tool for the main file created/edited in the conversation. Use kind "file" and pass the written file path.
        Prefer dashboard or metrics view files over other files.

        Task: The default OLAP connector is misconfigured. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 78a6c845fe0047b5
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 78a6c845fe0047b5
      content: '{"default_olap_connector":"duckdb_missing","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 8c0ed2d430ee4f27
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 8c0ed2d430ee4f27
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_7QUr3dE0kD6ZHvf3tlp0Frfc
      tool_name: read_file
      content: '{"path":"/rill.yaml"}'
- index: 4
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: user
      content_type: text
      content: |-
        For context, here are some details about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
        Note that you can only use it in model resources if it is not readonly.

        Call "navigate" tool for the main file created/edited in the conversation. Use kind "file" and pass the written file path.
        Prefer dashboard or metrics view files over other files.

        Task: The default OLAP connector is misconfigured. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 78a6c845fe0047b5
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 78a6c845fe0047b5
      content: '{"default_olap_connector":"duckdb_missing","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 8c0ed2d430ee4f27
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 8c0ed2d430ee4f27
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: fb31d74d2cd74563
      tool_name: read_file
      content: '{"path":"/rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: fb31d74d2cd74563
      content: '{"Contents":"olap_connector: duckdb_missing"}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_n2o2ToU1CNsb6TPiuY4ytkuG
      tool_name: develop_file
      content: '{"path":"/rill.yaml","prompt":"Fix the project''s default OLAP connector misconfiguration. The project currently sets `olap_connector: duckdb_missing`, which errors as unknown connector. There is an existing connector resource named `duckdb` at /connectors/duckdb.yaml and it reconciles successfully. Update rill.yaml to set `olap_connector: duckdb`. Keep the file minimal and valid YAML. Do not add unrelated settings.","type":"rill.yaml"}'
- index: 5
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: system
      content_type: text
      content: "# Instructions for developing `rill.yaml`\n\n## Introduction\n\n`rill.yaml` is a required configuration file located at the root of every Rill project. It defines project-wide settings, similar to `package.json` in Node.js or `dbt_project.yml` in dbt.\n\n## Core Concepts\n\n### Project metadata\n\nThere are no required properties in `rill.yaml`, but it is common to configure:\n\n- `display_name`: Human-readable name shown in the UI\n- `description`: Brief description of the project's purpose\n- `compiler`: Deprecated property that is commonly found in old projects\n\n### Default OLAP connector\n\nThe `olap_connector` property sets the default OLAP database for the project. Models output to this connector by default, and metrics views query from it unless explicitly overridden.\n\nCommon values are `duckdb` or `clickhouse`. If not specified, Rill initializes a managed DuckDB database and uses it as the default OLAP connector. \n\n### Mock users for security testing\n\nThe `mock_users` property defines test users for validating security policies during local development. Each mock user can have:\n\n- `email` (required): The user's email address\n- `name`: Display name\n- `admin`: Boolean indicating admin privileges\n- `groups`: List of group memberships\n- Custom attributes for use in security policy expressions\n\nWhen mock users are defined and security policies exist, a \"View as\" dropdown appears in the dashboard preview.\n\n### Environment variables\n\nThe `env` property sets default values for non-sensitive variables. These can be referenced in resource files using templating syntax (`{{ .env.<variable> }}`). Sensitive secrets should go in `.env` instead.\n\n### Resource type defaults\n\nProject-wide defaults can be set for resource types using plural keys:\n\n- `models`: Default settings for all models (e.g., refresh schedules)\n- `metrics_views`: Default settings for all metrics views (e.g., `first_day_of_week`)\n- `explores`: Default settings for explore dashboards (e.g., `time_ranges`, `time_zones`)\n- `canvases`: Default settings for canvas dashboards\n\nIndividual resources can override these defaults.\n\n### Path management\n\n- `ignore_paths`: List of paths to exclude from parsing (use leading `/`)\n- `public_paths`: List of paths to expose over HTTP (defaults to `['./public']`)\n\n### Environment overrides\n\nThe `dev` and `prod` properties allow environment-specific configuration overrides.\n\n## JSON Schema\n\nHere is a full JSON schema for the `rill.yaml` syntax:\n\n```\n$schema: http://json-schema.org/draft-07/schema#\nallOf:\n    - properties:\n        ai_connector:\n            description: Specifies the default AI connector for the project. Defaults to Rill's internal AI connector if not set.\n            type: string\n        ai_instructions:\n            description: Extra instructions for LLM/AI features. Used to guide natural language question answering and routing.\n            type: string\n        compiler:\n            description: Specifies the parser version to use for compiling resources\n            type: string\n        description:\n            description: A brief description of the project\n            type: string\n        display_name:\n            description: The display name of the project, shown in the upper-left corner of the UI\n            type: string\n        features:\n            description: Optional feature flags. Can be specified as a map of feature names to booleans.\n            type: object\n      title: Properties\n      type: object\n    - description: |\n        Rill allows you to specify the default OLAP engine to use in your project via `rill.yaml`.\n        :::info Curious about OLAP Engines?\n        Please see our reference documentation on [OLAP Engines](/developers/build/connectors/olap).\n        :::\n      properties:\n        olap_connector:\n            description: Specifies the default OLAP engine for the project. Defaults to duckdb if not set.\n            examples:\n                - olap_connector: clickhouse\n            type: string\n      title: Configuring the default OLAP Engine\n      type: object\n    - description: |\n        In `rill.yaml`, project-wide defaults can be specified for a resource type within a project. Unless otherwise specified, _individual resources will inherit any defaults_ that have been specified in `rill.yaml`. For available properties that can be configured, please refer to the YAML specification for each individual resource type - [model](models.md), [metrics_view](metrics-views.md), and [explore](explore-dashboards.md)\n\n        :::note Use plurals when specifying project-wide defaults\n        In your `rill.yaml`, the top level property for the resource type needs to be **plural**, such as `models`, `metrics_views` and `explores`.\n        :::\n\n        :::info Hierarchy of inheritance and property overrides\n        As a general rule of thumb, properties that have been specified at a more _granular_ level will supercede or override higher level properties that have been inherited. Therefore, in order of inheritance, Rill will prioritize properties in the following order:\n        1. Individual [models](models.md)/[metrics_views](metrics-views.md)/[explore](explore-dashboards.md) object level properties (e.g. `models.yaml` or `explore-dashboards.yaml`)\n        2. [Environment](/developers/build/models/templating) level properties (e.g. a specific property that have been set for `dev`)\n        3. [Project-wide defaults](#project-wide-defaults) for a specific property and resource type\n        :::\n      properties:\n        canvases:\n            description: Defines project-wide default settings for canvases. Unless overridden, individual canvases will inherit these defaults.\n            examples:\n                - canvases:\n                    defaults:\n                        time_range: P7D\n                    time_ranges:\n                        - PT24H\n                        - P7D\n                    time_zones:\n                        - UTC\n                  explores:\n                    defaults:\n                        time_range: P24M\n                    time_ranges:\n                        - PT24H\n                        - P6M\n                    time_zones:\n                        - UTC\n                  metrics_views:\n                    first_day_of_week: 1\n                    smallest_time_grain: month\n                  models:\n                    refresh:\n                        cron: 0 * * * *\n            type: object\n        explores:\n            description: Defines project-wide default settings for explores. Unless overridden, individual explores will inherit these defaults.\n            type: object\n        metrics_views:\n            description: Defines project-wide default settings for metrics_views. Unless overridden, individual metrics_views will inherit these defaults.\n            type: object\n        models:\n            description: Defines project-wide default settings for models. Unless overridden, individual models will inherit these defaults.\n            type: object\n      title: Project-wide defaults\n      type: object\n    - description: \"Primarily useful for [templating](/developers/build/connectors/templating), variables can be set in the `rill.yaml` file directly. This allows variables to be set for your projects deployed to Rill Cloud while still being able to use different variable values locally if you prefer. \\n:::info Overriding variables locally\\nVariables also follow an order of precedence and can be overridden locally. By default, any variables defined will be inherited from `rill.yaml`. However, if you manually pass in a variable when starting Rill Developer locally via the CLI, this value will be used instead for the current instance of your running project:\\n```bash\\nrill start --env numeric_var=100 --env string_var=\\\"different_value\\\"\\n```\\n:::\\n:::tip Setting variables through `.env`\\nVariables can also be set through your project's `<RILL_PROJECT_HOME>/.env` file (or using the `rill env set` CLI command), such as:\\n```bash\\nvariable=xyz\\n```\\nSimilar to how [connector credentials can be pushed / pulled](/developers/build/connectors/credentials#pulling-credentials-and-variables-from-a-deployed-project-on-rill-cloud) from local to cloud or vice versa, project variables set locally in Rill Developer can be pushed to Rill Cloud and/or pulled back to your local instance from your deployed project by using the `rill env push` and `rill env pull` commands respectively.\\n:::\\n\"\n      properties:\n        env:\n            description: To define a variable in `rill.yaml`, pass in the appropriate key-value pair for the variable under the `env` key\n            examples:\n                - env:\n                    numeric_var: 10\n                    string_var: string_value\n            type: object\n      title: Setting variables\n      type: object\n    - description: |\n        The public_paths and ignore_paths properties in the rill.yaml file provide control over which files and directories are processed or exposed by Rill. The public_paths property defines a list of file or directory paths to expose over HTTP. By default, it includes ['./public']. The ignore_paths property specifies a list of files or directories that Rill excludes during ingestion and parsing. This prevents unnecessary or incompatible content from affecting the project.\n        :::tip\n        Don't forget the leading `/` when specifying the path for `ignore_paths` and this path is also assuming the relative path from your project root.\n        :::\n      properties:\n        ignore_paths:\n            description: A list of file or directory paths to exclude from parsing. Useful for ignoring extraneous or non-Rill files in the project\n            examples:\n                - ignore_paths:\n                    - /path/to/ignore\n                    - /file_to_ignore.yaml\n            items:\n                type: string\n            type: array\n        public_paths:\n            description: List of file or directory paths to expose over HTTP. Defaults to ['./public']\n            items:\n                type: string\n            type: array\n      title: Managing Paths in Rill\n      type: object\n    - description: \"During development, it is always a good idea to check if your [access policies](/developers/build/metrics-view/security) are behaving the way you designed them to before pushing these changes into production. You can set mock users which enables a drop down in the dashboard preview to view as a specific user. \\n:::info The View as selector is not visible in my dashboard, why?\\nThis feature is _only_ enabled when you have set a security policy on the dashboard. By default, the dashboard and it's contents is viewable by every user.\\n:::\\n\"\n      properties:\n        mock_users:\n            description: A list of mock users used to test dashboard security policies within the project\n            examples:\n                - mock_users:\n                    - admin: true\n                      email: john@yourcompany.com\n                      name: John Doe\n                    - email: jane@partnercompany.com\n                      groups:\n                        - partners\n                    - email: anon@unknown.com\n                    - custom_variable_1: Value_1\n                      custom_variable_2: Value_2\n                      email: embed@rilldata.com\n                      name: embed\n            items:\n                properties:\n                    admin:\n                        description: Indicates whether the mock user has administrative privileges\n                        type: boolean\n                    email:\n                        description: The email address of the mock user. This field is required\n                        type: string\n                    groups:\n                        description: An array of group names that the mock user is a member of\n                        items:\n                            type: string\n                        type: array\n                    name:\n                        description: The name of the mock user.\n                        type: string\n                required:\n                    - email\n                type: object\n            type: array\n      title: Testing access policies\n      type: object\n    - properties:\n        dev:\n            description: Overrides any properties in development environment.\n            type: object\n        prod:\n            description: Overrides any properties in production environment.\n            type: object\n      title: Common Properties\n      type: object\ndescription: The `rill.yaml` file contains metadata about your project.\nid: rill-yaml.schema.yaml\ntitle: Project YAML\ntype: object\n```\n\n## Minimal Example\n\nA minimal `rill.yaml` for a new project:\n\n```yaml\ndisplay_name: My Analytics Project\n```\n\n## Complete Example\n\nA comprehensive `rill.yaml` demonstrating common configurations:\n\n```yaml\ndisplay_name: Sales Analytics\ndescription: Sales performance dashboards with partner access controls\n\nolap_connector: duckdb\n\n# Non-sensitive environment variables\nenv:\n  default_lookback: P30D\n  data_bucket: gs://my-company-data\n\n# Mock users for testing security policies locally\nmock_users:\n  - email: admin@mycompany.com\n    name: Admin User\n    admin: true\n  - email: partner@external.com\n    groups:\n      - partners\n  - email: viewer@mycompany.com\n    tenant_id: xyz\n\n# Project-wide defaults for models\nmodels:\n  refresh:\n    cron: 0 0 * * *\n\n# Project-wide defaults for metrics views\nmetrics_views:\n  smallest_time_grain: day\n\n# Project-wide defaults for explore dashboards\nexplores:\n  defaults:\n    time_range: P3M\n  time_zones:\n    - UTC\n    - America/New_York\n    - Europe/London\n  time_ranges:\n    - PT24H\n    - P7D\n    - P30D\n    - P3M\n    - P12M\n\n# Exclude non-Rill files from parsing\nignore_paths:\n  - /docs\n```"
    - role: user
      content_type: text
      content: |-
        You should develop a Rill project file based on the following task description:
        - Develop file at path: /rill.yaml
        - The file should be of type: rill.yaml
        - Task description: Fix the project's default OLAP connector misconfiguration. The project currently sets `olap_connector: duckdb_missing`, which errors as unknown connector. There is an existing connector resource named `duckdb` at /connectors/duckdb.yaml and it reconciles successfully. Update rill.yaml to set `olap_connector: duckdb`. Keep the file minimal and valid YAML. Do not add unrelated settings.

        Here is some important context:
        - You are running as a sub-agent of a larger developer agent. Stay aligned on your specific task and avoid extra discovery.
        - When you call 'write_file', if it returns a parse or reconcile error, do your best to fix the issue and try again. If you think the error is unrelated to the current path, let the parent agent know to handle it.

        Here is some additional context that may or may not be relevant to your task:
        - Info about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
  response:
    - role: assistant
      content_type: tool_call
      id: call_hjVvp0VjsAPMy511hy57ubU2
      tool_name: write_file
      content: '{"contents":"olap_connector: duckdb\n","path":"rill.yaml"}'
- index: 6
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: system
      content_type: text
      content: "# Instructions for developing `rill.yaml`\n\n## Introduction\n\n`rill.yaml` is a required configuration file located at the root of every Rill project. It defines project-wide settings, similar to `package.json` in Node.js or `dbt_project.yml` in dbt.\n\n## Core Concepts\n\n### Project metadata\n\nThere are no required properties in `rill.yaml`, but it is common to configure:\n\n- `display_name`: Human-readable name shown in the UI\n- `description`: Brief description of the project's purpose\n- `compiler`: Deprecated property that is commonly found in old projects\n\n### Default OLAP connector\n\nThe `olap_connector` property sets the default OLAP database for the project. Models output to this connector by default, and metrics views query from it unless explicitly overridden.\n\nCommon values are `duckdb` or `clickhouse`. If not specified, Rill initializes a managed DuckDB database and uses it as the default OLAP connector. \n\n### Mock users for security testing\n\nThe `mock_users` property defines test users for validating security policies during local development. Each mock user can have:\n\n- `email` (required): The user's email address\n- `name`: Display name\n- `admin`: Boolean indicating admin privileges\n- `groups`: List of group memberships\n- Custom attributes for use in security policy expressions\n\nWhen mock users are defined and security policies exist, a \"View as\" dropdown appears in the dashboard preview.\n\n### Environment variables\n\nThe `env` property sets default values for non-sensitive variables. These can be referenced in resource files using templating syntax (`{{ .env.<variable> }}`). Sensitive secrets should go in `.env` instead.\n\n### Resource type defaults\n\nProject-wide defaults can be set for resource types using plural keys:\n\n- `models`: Default settings for all models (e.g., refresh schedules)\n- `metrics_views`: Default settings for all metrics views (e.g., `first_day_of_week`)\n- `explores`: Default settings for explore dashboards (e.g., `time_ranges`, `time_zones`)\n- `canvases`: Default settings for canvas dashboards\n\nIndividual resources can override these defaults.\n\n### Path management\n\n- `ignore_paths`: List of paths to exclude from parsing (use leading `/`)\n- `public_paths`: List of paths to expose over HTTP (defaults to `['./public']`)\n\n### Environment overrides\n\nThe `dev` and `prod` properties allow environment-specific configuration overrides.\n\n## JSON Schema\n\nHere is a full JSON schema for the `rill.yaml` syntax:\n\n```\n$schema: http://json-schema.org/draft-07/schema#\nallOf:\n    - properties:\n        ai_connector:\n            description: Specifies the default AI connector for the project. Defaults to Rill's internal AI connector if not set.\n            type: string\n        ai_instructions:\n            description: Extra instructions for LLM/AI features. Used to guide natural language question answering and routing.\n            type: string\n        compiler:\n            description: Specifies the parser version to use for compiling resources\n            type: string\n        description:\n            description: A brief description of the project\n            type: string\n        display_name:\n            description: The display name of the project, shown in the upper-left corner of the UI\n            type: string\n        features:\n            description: Optional feature flags. Can be specified as a map of feature names to booleans.\n            type: object\n      title: Properties\n      type: object\n    - description: |\n        Rill allows you to specify the default OLAP engine to use in your project via `rill.yaml`.\n        :::info Curious about OLAP Engines?\n        Please see our reference documentation on [OLAP Engines](/developers/build/connectors/olap).\n        :::\n      properties:\n        olap_connector:\n            description: Specifies the default OLAP engine for the project. Defaults to duckdb if not set.\n            examples:\n                - olap_connector: clickhouse\n            type: string\n      title: Configuring the default OLAP Engine\n      type: object\n    - description: |\n        In `rill.yaml`, project-wide defaults can be specified for a resource type within a project. Unless otherwise specified, _individual resources will inherit any defaults_ that have been specified in `rill.yaml`. For available properties that can be configured, please refer to the YAML specification for each individual resource type - [model](models.md), [metrics_view](metrics-views.md), and [explore](explore-dashboards.md)\n\n        :::note Use plurals when specifying project-wide defaults\n        In your `rill.yaml`, the top level property for the resource type needs to be **plural**, such as `models`, `metrics_views` and `explores`.\n        :::\n\n        :::info Hierarchy of inheritance and property overrides\n        As a general rule of thumb, properties that have been specified at a more _granular_ level will supercede or override higher level properties that have been inherited. Therefore, in order of inheritance, Rill will prioritize properties in the following order:\n        1. Individual [models](models.md)/[metrics_views](metrics-views.md)/[explore](explore-dashboards.md) object level properties (e.g. `models.yaml` or `explore-dashboards.yaml`)\n        2. [Environment](/developers/build/models/templating) level properties (e.g. a specific property that have been set for `dev`)\n        3. [Project-wide defaults](#project-wide-defaults) for a specific property and resource type\n        :::\n      properties:\n        canvases:\n            description: Defines project-wide default settings for canvases. Unless overridden, individual canvases will inherit these defaults.\n            examples:\n                - canvases:\n                    defaults:\n                        time_range: P7D\n                    time_ranges:\n                        - PT24H\n                        - P7D\n                    time_zones:\n                        - UTC\n                  explores:\n                    defaults:\n                        time_range: P24M\n                    time_ranges:\n                        - PT24H\n                        - P6M\n                    time_zones:\n                        - UTC\n                  metrics_views:\n                    first_day_of_week: 1\n                    smallest_time_grain: month\n                  models:\n                    refresh:\n                        cron: 0 * * * *\n            type: object\n        explores:\n            description: Defines project-wide default settings for explores. Unless overridden, individual explores will inherit these defaults.\n            type: object\n        metrics_views:\n            description: Defines project-wide default settings for metrics_views. Unless overridden, individual metrics_views will inherit these defaults.\n            type: object\n        models:\n            description: Defines project-wide default settings for models. Unless overridden, individual models will inherit these defaults.\n            type: object\n      title: Project-wide defaults\n      type: object\n    - description: \"Primarily useful for [templating](/developers/build/connectors/templating), variables can be set in the `rill.yaml` file directly. This allows variables to be set for your projects deployed to Rill Cloud while still being able to use different variable values locally if you prefer. \\n:::info Overriding variables locally\\nVariables also follow an order of precedence and can be overridden locally. By default, any variables defined will be inherited from `rill.yaml`. However, if you manually pass in a variable when starting Rill Developer locally via the CLI, this value will be used instead for the current instance of your running project:\\n```bash\\nrill start --env numeric_var=100 --env string_var=\\\"different_value\\\"\\n```\\n:::\\n:::tip Setting variables through `.env`\\nVariables can also be set through your project's `<RILL_PROJECT_HOME>/.env` file (or using the `rill env set` CLI command), such as:\\n```bash\\nvariable=xyz\\n```\\nSimilar to how [connector credentials can be pushed / pulled](/developers/build/connectors/credentials#pulling-credentials-and-variables-from-a-deployed-project-on-rill-cloud) from local to cloud or vice versa, project variables set locally in Rill Developer can be pushed to Rill Cloud and/or pulled back to your local instance from your deployed project by using the `rill env push` and `rill env pull` commands respectively.\\n:::\\n\"\n      properties:\n        env:\n            description: To define a variable in `rill.yaml`, pass in the appropriate key-value pair for the variable under the `env` key\n            examples:\n                - env:\n                    numeric_var: 10\n                    string_var: string_value\n            type: object\n      title: Setting variables\n      type: object\n    - description: |\n        The public_paths and ignore_paths properties in the rill.yaml file provide control over which files and directories are processed or exposed by Rill. The public_paths property defines a list of file or directory paths to expose over HTTP. By default, it includes ['./public']. The ignore_paths property specifies a list of files or directories that Rill excludes during ingestion and parsing. This prevents unnecessary or incompatible content from affecting the project.\n        :::tip\n        Don't forget the leading `/` when specifying the path for `ignore_paths` and this path is also assuming the relative path from your project root.\n        :::\n      properties:\n        ignore_paths:\n            description: A list of file or directory paths to exclude from parsing. Useful for ignoring extraneous or non-Rill files in the project\n            examples:\n                - ignore_paths:\n                    - /path/to/ignore\n                    - /file_to_ignore.yaml\n            items:\n                type: string\n            type: array\n        public_paths:\n            description: List of file or directory paths to expose over HTTP. Defaults to ['./public']\n            items:\n                type: string\n            type: array\n      title: Managing Paths in Rill\n      type: object\n    - description: \"During development, it is always a good idea to check if your [access policies](/developers/build/metrics-view/security) are behaving the way you designed them to before pushing these changes into production. You can set mock users which enables a drop down in the dashboard preview to view as a specific user. \\n:::info The View as selector is not visible in my dashboard, why?\\nThis feature is _only_ enabled when you have set a security policy on the dashboard. By default, the dashboard and it's contents is viewable by every user.\\n:::\\n\"\n      properties:\n        mock_users:\n            description: A list of mock users used to test dashboard security policies within the project\n            examples:\n                - mock_users:\n                    - admin: true\n                      email: john@yourcompany.com\n                      name: John Doe\n                    - email: jane@partnercompany.com\n                      groups:\n                        - partners\n                    - email: anon@unknown.com\n                    - custom_variable_1: Value_1\n                      custom_variable_2: Value_2\n                      email: embed@rilldata.com\n                      name: embed\n            items:\n                properties:\n                    admin:\n                        description: Indicates whether the mock user has administrative privileges\n                        type: boolean\n                    email:\n                        description: The email address of the mock user. This field is required\n                        type: string\n                    groups:\n                        description: An array of group names that the mock user is a member of\n                        items:\n                            type: string\n                        type: array\n                    name:\n                        description: The name of the mock user.\n                        type: string\n                required:\n                    - email\n                type: object\n            type: array\n      title: Testing access policies\n      type: object\n    - properties:\n        dev:\n            description: Overrides any properties in development environment.\n            type: object\n        prod:\n            description: Overrides any properties in production environment.\n            type: object\n      title: Common Properties\n      type: object\ndescription: The `rill.yaml` file contains metadata about your project.\nid: rill-yaml.schema.yaml\ntitle: Project YAML\ntype: object\n```\n\n## Minimal Example\n\nA minimal `rill.yaml` for a new project:\n\n```yaml\ndisplay_name: My Analytics Project\n```\n\n## Complete Example\n\nA comprehensive `rill.yaml` demonstrating common configurations:\n\n```yaml\ndisplay_name: Sales Analytics\ndescription: Sales performance dashboards with partner access controls\n\nolap_connector: duckdb\n\n# Non-sensitive environment variables\nenv:\n  default_lookback: P30D\n  data_bucket: gs://my-company-data\n\n# Mock users for testing security policies locally\nmock_users:\n  - email: admin@mycompany.com\n    name: Admin User\n    admin: true\n  - email: partner@external.com\n    groups:\n      - partners\n  - email: viewer@mycompany.com\n    tenant_id: xyz\n\n# Project-wide defaults for models\nmodels:\n  refresh:\n    cron: 0 0 * * *\n\n# Project-wide defaults for metrics views\nmetrics_views:\n  smallest_time_grain: day\n\n# Project-wide defaults for explore dashboards\nexplores:\n  defaults:\n    time_range: P3M\n  time_zones:\n    - UTC\n    - America/New_York\n    - Europe/London\n  time_ranges:\n    - PT24H\n    - P7D\n    - P30D\n    - P3M\n    - P12M\n\n# Exclude non-Rill files from parsing\nignore_paths:\n  - /docs\n```"
    - role: user
      content_type: text
      content: |-
        You should develop a Rill project file based on the following task description:
        - Develop file at path: /rill.yaml
        - The file should be of type: rill.yaml
        - Task description: Fix the project's default OLAP connector misconfiguration. The project currently sets `olap_connector: duckdb_missing`, which errors as unknown connector. There is an existing connector resource named `duckdb` at /connectors/duckdb.yaml and it reconciles successfully. Update rill.yaml to set `olap_connector: duckdb`. Keep the file minimal and valid YAML. Do not add unrelated settings.

        Here is some important context:
        - You are running as a sub-agent of a larger developer agent. Stay aligned on your specific task and avoid extra discovery.
        - When you call 'write_file', if it returns a parse or reconcile error, do your best to fix the issue and try again. If you think the error is unrelated to the current path, let the parent agent know to handle it.

        Here is some additional context that may or may not be relevant to your task:
        - Info about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
    - role: assistant
      content_type: tool_call
      id: 1741eecd923e4284
      tool_name: write_file
      content: '{"contents":"olap_connector: duckdb\n","path":"rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: 1741eecd923e4284
      content: '{"diff":"--- /rill.yaml\n+++ /rill.yaml\n@@ -1 +1,2 @@\n-olap_connector: duckdb_missing\n+olap_connector: duckdb\n+\n"}'
  response:
    - role: assistant
      content_type: text
      content: |-
        Updated `/rill.yaml` to fix the default OLAP connector misconfiguration by setting it to the existing, successfully reconciled connector:

        ```yaml
        olap_connector: duckdb
        ```
- index: 7
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: user
      content_type: text
      content: |-
        For context, here are some details about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
        Note that you can only use it in model resources if it is not readonly.

        Call "navigate" tool for the main file created/edited in the conversation. Use kind "file" and pass the written file path.
        Prefer dashboard or metrics view files over other files.

        Task: The default OLAP connector is misconfigured. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 78a6c845fe0047b5
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 78a6c845fe0047b5
      content: '{"default_olap_connector":"duckdb_missing","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 8c0ed2d430ee4f27
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 8c0ed2d430ee4f27
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: fb31d74d2cd74563
      tool_name: read_file
      content: '{"path":"/rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: fb31d74d2cd74563
      content: '{"Contents":"olap_connector: duckdb_missing"}'
    - role: assistant
      content_type: tool_call
      id: ca7b76e9f6cc4d58
      tool_name: develop_file
      content: '{"path":"/rill.yaml","prompt":"Fix the project''s default OLAP connector misconfiguration. The project currently sets `olap_connector: duckdb_missing`, which errors as unknown connector. There is an existing connector resource named `duckdb` at /connectors/duckdb.yaml and it reconciles successfully. Update rill.yaml to set `olap_connector: duckdb`. Keep the file minimal and valid YAML. Do not add unrelated settings.","type":"rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: ca7b76e9f6cc4d58
      content: '{"response":"Updated `/rill.yaml` to fix the default OLAP connector misconfiguration by setting it to the existing, successfully reconciled connector:\n\n```yaml\nolap_connector: duckdb\n```"}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_gB5pWILsvRoilYTJQe1nn3Yd
      tool_name: project_status
      content: '{}'
- index: 8
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: user
      content_type: text
      content: |-
        For context, here are some details about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
        Note that you can only use it in model resources if it is not readonly.

        Call "navigate" tool for the main file created/edited in the conversation. Use kind "file" and pass the written file path.
        Prefer dashboard or metrics view files over other files.

        Task: The default OLAP connector is misconfigured. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 78a6c845fe0047b5
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 78a6c845fe0047b5
      content: '{"default_olap_connector":"duckdb_missing","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 8c0ed2d430ee4f27
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 8c0ed2d430ee4f27
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: fb31d74d2cd74563
      tool_name: read_file
      content: '{"path":"/rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: fb31d74d2cd74563
      content: '{"Contents":"olap_connector: duckdb_missing"}'
    - role: assistant
      content_type: tool_call
      id: ca7b76e9f6cc4d58
      tool_name: develop_file
      content: '{"path":"/rill.yaml","prompt":"Fix the project''s default OLAP connector misconfiguration. The project currently sets `olap_connector: duckdb_missing`, which errors as unknown connector. There is an existing connector resource named `duckdb` at /connectors/duckdb.yaml and it reconciles successfully. Update rill.yaml to set `olap_connector: duckdb`. Keep the file minimal and valid YAML. Do not add unrelated settings.","type":"rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: ca7b76e9f6cc4d58
      content: '{"response":"Updated `/rill.yaml` to fix the default OLAP connector misconfiguration by setting it to the existing, successfully reconciled connector:\n\n```yaml\nolap_connector: duckdb\n```"}'
    - role: assistant
      content_type: tool_call
      id: fc8c875df8be4496
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: fc8c875df8be4496
      content: '{"default_olap_connector":"duckdb","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
  response:
    - role: assistant
      content_type: tool_call
      id: call_Ee7cmXuvLDrqwPlYOqmtkWGr
      tool_name: navigate
      content: '{"kind":"file","name":"/rill.yaml"}'
- index: 9
  input:
    - role: system
      content_type: text
      content: "# Instructions for developing a Rill project\n\nThis document is intended for data engineering agents specialized in developing projects in the Rill business intelligence platform.\n\n## Introduction to Rill\n\nRill is a business intelligence platform built around the following principles:\n- Code-first: configure projects using versioned and reproducible source code in the form of YAML and SQL files.\n- Full stack: go from raw data sources to user-friendly dashboards powered by clean data with a single tool.\n- Declarative: describe your business logic and Rill automatically runs the infrastructure, migrations and services necessary to make it real.\n- OLAP databases: you can easily provision a fast analytical database and load data into it to build dashboards that stay interactive at scale.\n\n## Project structure\n\nA Rill project consists of resources that are defined using YAML and SQL files in the project's file directory.\nRill supports different resource types, such as connectors, models, metrics views, explore dashboards, and more.\n\nHere is an example listing of files for a small Rill project:\n```\n.env\nconnectors/duckdb.yaml\nconnectors/s3.yaml\nmodels/events_raw.yaml\nmodels/events.sql\nmetrics/events.yaml\ndashboards/events.yaml\nrill.yaml\n```\n\nLet's start with the project-wide files at the root of the directory:\n- `rill.yaml` is a required file that contains project-wide configuration. It can be compared to `package.json` in Node.js or `dbt_project.yml` in dbt.\n- `.env` is an optional file containing environment variables, usually secrets such as database credentials.\n\nThe other YAML and SQL files define individual resources in the project. They follow a few rules:\n- The YAML files must contain a `type:` property that identifies the resource type. The other properties in the file are specific to the selected resource type.\n- SQL files are a convenient way of creating model resources. They are equivalent to a YAML file with `type: model` and a `sql:` property.\n- Each file declares one main resource, but may in some cases also emit some dependent resources with internally generated names.\n- The main resource declared by a file gets a unique name derived from the filename by removing the directory name and extension. For example, `connectors/duckdb.yaml` defines a connector called `duckdb`.\n- Directories are ignored by the parser and can be used to organize the project as you see fit. Small projects often have one directory per resource type.\n- Resources can reference other resources, which forms a dependency graph (DAG) that informs the sequence they are executed.\n- Resource names are unique within a resource type. For example, only one model can be named `events` (regardless of directory), but it is possible for both a model and a metrics view to be called `events`.\n- Clear resource names are important as they are widely used as unique identifiers throughout the platform (e.g. in CLI commands, URL slugs, API calls). They are usually lowercase and snake case, but that is not enforced.\n\n## Project execution\n\nRill automatically watches project files and processes changes. There are two key phases:\n- **Parsing**: Files are converted into resources and organized into a DAG. Malformed files produce *parse errors*.\n- **Reconciliation**: Resources are executed to achieve their desired state. Failures produce *reconcile errors*.\n\nSome resources are cheap to reconcile (validation, non-materialized models), others are expensive (materialized models, managed connectors). Be cautious with expensive operations; see resource-specific instructions for details.\n\nResources can also have scheduled reconciliation via cron expressions (e.g. daily model refresh).\n\n## Rill's environments\n\nRill has a local CLI (`rill`) for development and a cloud service for production. After developing or changing a project locally, developers deploy to Rill Cloud either by pushing to GitHub (continuous deploys) or manually deploying with the CLI.\n\n## OLAP databases\n\nRill places high emphasis on \"operational intelligence\", meaning low-latency, high-performance, drill-down dashboards with support for alerts and scheduled reports.\nRill supports these features using OLAP databases and has drivers that are heavily optimized to leverage database-specific features to get high performance.\n\nOLAP databases are configured as any other connector in Rill.\nPeople can either connect an external OLAP database with existing tables, or can ask Rill to provision an empty OLAP database for them, which they can load data into using Rill's `model` resource type.\n\nOLAP connectors are currently the only connectors that can directly power the metrics views resources that in turn power dashboards. So data must be in an OLAP database to power a dashboard.\n\nSince OLAP databases have a special role in Rill, every project must have a _default_ OLAP connector that you configure using the `olap_connector:` property in `rill.yaml`. This default OLAP connector is automatically used for a variety of things in Rill unless explicitly overridden (see details under the resource type descriptions). If no OLAP connector is configured, Rill by default initializes a managed `duckdb` OLAP database and uses it as the default OLAP connector.\n\n## Resource types\n\nThe sections below contain descriptions of the different resource types that Rill supports and when to use them.\nThe descriptions are high-level; you can find detailed descriptions and examples in the separate resource-specific instruction files.\n\n### Connectors\n\nConnectors are resources containing credentials and settings for connecting to an external system.\nThey are usually lightweight as their reconcile logic usually only validates the connection.\nThey are normally found at the root of the DAG, powering other downstream resource types.\n\nThere are a variety of built-in connector _drivers_, which each implements one or more capabilities:\n- **OLAP database:** can power dashboards (e.g. `duckdb`, `clickhouse`)\n- **SQL database:** can run SQL queries and models (e.g. `postgres`, `bigquery`, `snowflake`)\n- **Information schema:** can list tables and their schemas (e.g. `duckdb`, `bigquery`, `postgres`)\n- **Object store:** can list, read and write flat files (e.g. `s3`)\n- **Notifier:** can send notifications (e.g. `slack`)\n\nHere are some useful things to know when developing connectors:\n- Actual secrets like database passwords should go in `.env` and be referenced from the connector's YAML file\n- Connectors are usually called the same as their driver, unless there are multiple connectors that use the same driver.\n- OLAP connectors with the property `managed: true` will automatically be provisioned by Rill, so you don't need to handle the infrastructure or credentials directly. This is only supported for the `duckdb` and `clickhouse` drivers. The user will be subject to usage-based billing for the CPU, memory and disk usage of the provisioned database.\n- User-configured OLAP connectors with externally managed tables should have `mode: read` to protect from unintended writes from Rill models.\n- The primary OLAP connector used in a project should be configured in `rill.yaml` using the `olap_connector:` property.\n\n### Models\n\nModels are resources that specify ETL or transformation logic that outputs a tabular dataset in one of the project's connectors.\nThey are usually expensive resources that are found near the root of the DAG, referencing only connectors and other models.\n\nModels usually (and by default) output data as a table with the same name as the model in the project's default OLAP connector.\nThey usually center around a `SELECT` SQL statement that Rill will run as a `CREATE TABLE <name> AS <SELECT statement>`.\nThis means models in Rill are similar to models in dbt, but they support some additional advanced features, namely:\n- Different input and output connectors (making it easy to e.g. run a query in BigQuery and output it to the default OLAP connector)\n- Stateful incremental ingestion with support for explicit partitions (e.g. for loading Hive partitioned files from S3)\n- Scheduled refresh using a cron expression in the model itself\n\nWhen reasoning about a model, it can be helpful to think in terms of the following attributes:\n- **Source model:** references external data, usually reading data from a SQL or object store connector and writing it into an OLAP connector\n- **Derived model:** references other models, usually doing joins or formatting columns to prepare a denormalized table suitable for use in metrics views and dashboards \n- **Materialized model:** outputs a physical table (i.e. not just a SQL view)\n- **Incremental model:** has logic for incrementally loading data\n- **Partitioned model:** capable of loading data in well-defined increments, such as daily partitions, enabling scalability and idempotent incremental runs\n\nModels are usually expensive resources that can take a long time to run, and should be created or edited with caution.\nThe only exception is non-materialized models that have the same input and output connector, which get created as cheap SQL views.\nIn development, you can avoid expensive operations by adding a \"dev partition\", which limits data processed to a subset. See the instructions for model development for details.\n\n### Metrics views\n\nMetrics views are resources that define queryable business metrics on top of a table in an OLAP database.\nThey implement what other business intelligence tools call a \"semantic layer\" or \"metrics layer\".\nThey are lightweight resources found downstream of connectors and models in the DAG.\nThey power many user-facing features, such as dashboards, alerts, and scheduled reports.\n\nMetrics views consist of:\n- **Model:** a table in an OLAP database; can either be a pre-existing table in an external OLAP database or a table produced by a model in the Rill project\n- **Dimensions:** SQL expressions that can be grouped by (e.g. time, string or geospatial types)\n- **Measures:** SQL expressions that define aggregations (usually numeric types)\n- **Security policies:** access rules and row filters that reference attributes of the querying user\n\n### Explores\n\nExplore resources define an \"explore dashboard\", an opinionated dashboard type that comes baked into Rill.\nThese dashboards are specifically designed as an explorative, drill-down, slice-and-dice interface for a single metrics view.\nThey are Rill's default dashboard type, and usually configured for every metrics view in a project.\nThey are lightweight resources that are always found downstream of a metrics view in the DAG.\n\nExplore resources can either be configured as stand-alone files or as part of a metrics view definition (see metrics view instructions for details).\nThe only required configuration is a metrics view to render, but you can optionally also configure things like a theme, default dimension and measures to show, time range presets, and more.\n\n### Canvases\n\nCanvas resources configure a \"canvas dashboard\", which is a free-form dashboard type consisting of custom chart and table components laid out in a grid.\nThey enable users to build overview/report style dashboards with limited drill-down options, similar to those found in traditional business intelligence tools.\n\nCanvas dashboards support a long list of component types, including line charts, bar charts, pie charts, markdown text, tables, and more.\nAll components are defined in the canvas file, but each component is emitted as a separate resource of type `component`, which gets placed upstream of the canvas in the project DAG.\nEach canvas component fetches data individually, almost always from a metrics view resource; so you often find metrics view resources upstream of components in the DAG.\n\n### Themes\n\nThemes are resources that define a custom color palette for a Rill project.\nThey are referenced from `rill.yaml` or directly from an explore or canvas dashboards.\n\n### Custom APIs\n\nCustom APIs are resources that define a query that serves data from the Rill project on a custom endpoint.\nThey are advanced resources that enable easy programmatic integration with a Rill project.\nThey are lightweight resources that are usually found downstream of metrics views in the DAG (but sometimes directly downstream of a connector or model).\n\nCustom APIs are mounted as `GET` and `POST` REST APIs on `<project URL>/api/<resource name>`.\nThe queries can use templating to inject request parameters or user attributes.\n\nRill supports a number of different \"data resolver\" types, which execute queries and return data.\nThe most common ones are:\n- `metrics_sql`: queries a metrics view using a generic SQL syntax (recommended)\n- `metrics`: queries a metrics view using a structured query object\n- `sql`: queries an OLAP connector using a raw SQL query in its native SQL dialect\n\n### Alerts\n\nAlerts are resources that enable sending alerts when certain criteria matches data in the Rill project.\nThey consists of a refresh schedule, a query to execute, and notification settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define alerts directly as files; instead, users can define alerts using a UI in Rill Cloud.\n\n### Reports\n\nReports are resources that enable sending scheduled reports of data in the project.\nThey consists of a delivery schedule, a query to execute, and delivery settings.\nSince they repeatedly run a query, they are slightly expensive resources.\nThey are usually found downstream of a metrics view in the DAG.\nMost projects don't define reports directly as files; instead, users can define reports using a UI in Rill Cloud.\n\n### `rill.yaml`\n\n`rill.yaml` is a required file for project-wide config found at the root directory of a Rill project.\nIt is mainly used for:\n- Setting shared properties for all resources of a given type (e.g. giving all dashboards the same theme)\n- Setting default values for non-sensitive environment variables\n- Customizing feature flags\n- Configuring mock users for testing security policies locally\n\n### `.env`\n\n`.env` is an optional file containing environment variables, which Rill loads when running the project.\nOther resources can reference these environment variables using a templating syntax.\nBy convention, environment variables in Rill use snake-case, lowercase names (this differs from shell environment variables).\n\n## Development process\n\nThis section describes the recommended workflow for developing resources in a Rill project.\n\n### Understanding the task\n\nBefore making changes, determine what kind of task you are performing:\n- **Querying**: If you need to answer a question about data in the project, use query tools but do not modify files.\n- **Surgical edit**: If you need to create or update a single resource, focus on that resource and its immediate dependencies.\n- **Full pipeline**: If you need to go from raw data to dashboard, expect your changes to cover a sequential pipeline through connector(s), source model(s), derived model(s), metrics view(s), and an explore or canvas dashboard.\n\n### Checking project capabilities\n\nBefore proceeding, verify what the project supports:\n- **Write access**: Do you have access to modify files in the project? If not, you are limited to explaining the project or guiding the developer.\n- **Data access**: Does the project have a connector for the relevant data source? If not, you need to create a connector and add the required credentials to `.env`, then ask the user to populate those values before continuing.\n- **OLAP mode**: Is the default OLAP connector read-only or readwrite? If read-only, you cannot create models; instead, create metrics views and dashboards directly on existing tables in the OLAP database.\n\n### Recommended workflow\n\nYour workflow will depend on the kind of task you are undertaking. Here follows an idealized workflow for a full data source to dashboard journey:\n\n1. **Survey existing resources**: Check what resources already exist in the project using the project status and file tools. You may be able to reuse or extend existing models, metrics views, or dashboards rather than creating new ones.\n2. **Explore available data**: Use connector introspection tools to discover what tables or files are available. For SQL databases, query the information schema. For object stores, list buckets and files.\n3. **Handle missing data**: If the project lacks access to the data you need, ask the user whether to generate mock data or help them configure a connector to their data source.\n4. **Create or update models** (managed or readwrite OLAP only): Build models that ingest and transform data into denormalized tables suitable for dashboard queries. Materialize models that involve expensive joins or aggregations. Use dev partitions to limit data during development.\n5. **Profile the data**: Before creating a metrics view, look at the schema of the underlying model/table to understand its shape. This informs which dimensions and measures you create. Consider using the SQL query tool to do a couple well-chosen queries to the table to get row counts, cardinality of important columns, example column values, date ranges, or similar. Be very careful not to run too many queries or expensive queries.\n6. **Create or update the metrics view**: Define dimensions and measures using columns in the underlying model/table. Start small with one time dimension (timeseries), up to 10 dimensions and up to 5 measures, and add more later if relevant.\n7. **Ensure there are dashboards**: Create an explore dashboard for drill-down analysis of the metrics view if one doesn't already exist. If the user wants an overview or report-style view, also create a canvas dashboard with components from one or more metrics views.\n8. **Keep iterating until errors are fixed:** At each stage, if there are parse or reconcile errors, keep updating the relevant file(s) to fix the error.\n\n### Available tools\n\nThe following tools are typically available for project development:\n\n- `file_list`, `file_search` and `file_read` for accessing existing files in the project\n- `develop_file` for delegating file development to a sub-agent, which handles writing and iterating on errors\n- `file_write` for directly creating, updating or deleting a file (available to sub-agents; waits for parse/reconcile and returns resource status)\n\n- `project_status` for checking resource names and their current status (idle, running, error)\n- `query_sql` for running SQL against a connector; use `SELECT` statements with `LIMIT` clauses and low timeouts, and be mindful of performance or making too many queries\n- `query_metrics_view` for querying a metrics view; useful for answering data questions and validating dashboard behavior\n- `list_tables` and `get_table` for accessing the information schema of a database connector\n- `list_buckets` and `list_bucket_files` for exploring files in object stores like S3 or GCS; to preview file contents, load one file into a table using a model and query it with `query_sql`\n\n\n\n### Common pitfalls\n\nAvoid these mistakes when developing a project:\n- **Duplicating ETL logic**: Ingest data once, then derive from it within the project. Do not create multiple models that pull the same data from an external source.\n- **Models as SQL files:** Always create new models as `.yaml` files, not `.sql` files (which are harder to extend later).\n- **Not creating connector files:** When Rill has native support for a connector (like S3 or BigQuery), always create a dedicated connector resource file for it.\n- **Forgetting to materialize**: Always materialize models that reference external data or perform expensive operations. This also includes models that load external data using a native SQL function, like `read_parquet(...)` or `s3(...)`. Non-materialized models become views, which re-execute on every query.\n- **Referencing non-existant environment variables:** Only reference environment variables that are present in `.env` (returned in `env` from `project_status`). If you need the user to add another environment variable, stop and ask them to do so.\n- **Processing too much data in development**: Use dev partitions to limit data to a small subset (e.g., one day) during development. This speeds up iteration and avoids unnecessary costs.\n- **Not adding a time dimension (timeseries) in metrics views**: Metrics views are much more useful when they have a time dimension. Make sure to set one of them as the primary time dimension using the `timeseries:` property.\n\n- **Doing too much introspection/profiling:** Reading files, introspecting connectors, profiling models/tables can be time consuming and easily load too much context. Stay disciplined and don't do too much open-ended exploration or unnecessarily look into other levels of the DAG, especially if your task is a small/surgical edit.\n- **Not using the `develop_file` tool:** You should plan the changes you want to make first, then delegate each change separately to the `develop_file` tool. When calling `develop_file`, pass in any relevant context from your investigation/planning/profiling phase.\n- **Doing too much at a time:** Consider the minimal amount of work to accomplish your current task. It's better to make changes incrementally and let the user guide your work.\n- **Don't stop if there are errors:** When a file has an error after you made changes, keep looping until you have done your best to fix the error. You should not give up easily, the user does expect you to try and fix errors.\n"
    - role: user
      content_type: text
      content: |-
        For context, here are some details about the project's default OLAP connector: name: "duckdb_missing", error: unknown connector "duckdb_missing".
        Note that you can only use it in model resources if it is not readonly.

        Call "navigate" tool for the main file created/edited in the conversation. Use kind "file" and pass the written file path.
        Prefer dashboard or metrics view files over other files.

        Task: The default OLAP connector is misconfigured. Can you fix it?
    - role: assistant
      content_type: tool_call
      id: 78a6c845fe0047b5
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 78a6c845fe0047b5
      content: '{"default_olap_connector":"duckdb_missing","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: 8c0ed2d430ee4f27
      tool_name: list_files
      content: '{}'
    - role: tool
      content_type: tool_response
      id: 8c0ed2d430ee4f27
      content: '{"files":[{"path":"/connectors/duckdb.yaml","resources":[{"kind":"rill.runtime.v1.Connector","name":"duckdb","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE"}]},{"path":"/rill.yaml"}]}'
    - role: assistant
      content_type: tool_call
      id: fb31d74d2cd74563
      tool_name: read_file
      content: '{"path":"/rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: fb31d74d2cd74563
      content: '{"Contents":"olap_connector: duckdb_missing"}'
    - role: assistant
      content_type: tool_call
      id: ca7b76e9f6cc4d58
      tool_name: develop_file
      content: '{"path":"/rill.yaml","prompt":"Fix the project''s default OLAP connector misconfiguration. The project currently sets `olap_connector: duckdb_missing`, which errors as unknown connector. There is an existing connector resource named `duckdb` at /connectors/duckdb.yaml and it reconciles successfully. Update rill.yaml to set `olap_connector: duckdb`. Keep the file minimal and valid YAML. Do not add unrelated settings.","type":"rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: ca7b76e9f6cc4d58
      content: '{"response":"Updated `/rill.yaml` to fix the default OLAP connector misconfiguration by setting it to the existing, successfully reconciled connector:\n\n```yaml\nolap_connector: duckdb\n```"}'
    - role: assistant
      content_type: tool_call
      id: fc8c875df8be4496
      tool_name: project_status
      content: '{}'
    - role: tool
      content_type: tool_response
      id: fc8c875df8be4496
      content: '{"default_olap_connector":"duckdb","env":["connector.openai.api_key"],"resources":[{"kind":"rill.runtime.v1.ProjectParser","name":"parser","path":"","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]},{"kind":"rill.runtime.v1.Connector","name":"duckdb","path":"/connectors/duckdb.yaml","reconcile_error":"","reconcile_status":"RECONCILE_STATUS_IDLE","refs":[]}],"parse_errors":[]}'
    - role: assistant
      content_type: tool_call
      id: d7fa28f745764c92
      tool_name: navigate
      content: '{"kind":"file","name":"/rill.yaml"}'
    - role: tool
      content_type: tool_response
      id: d7fa28f745764c92
      content: '{}'
  response:
    - role: assistant
      content_type: text
      content: |-
        Updated the projects default OLAP connector to point to the existing, valid connector.

        - **Changed:** `/rill.yaml`
        - **From:** `olap_connector: duckdb_missing` (unknown connector)
        - **To:** `olap_connector: duckdb`

        `project_status` now shows `default_olap_connector: "duckdb"` with no parse or reconcile errors.
