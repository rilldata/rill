$schema: 'http://json-schema.org/draft-07/schema#'
$id: advanced-models.schema.yaml
title: Models YAML
type: object
description: |
    :::tip

    Both regular models and source models can use the Model YAML specification described on this page. While [SQL models](./models) are perfect for simple transformations, Model YAML files provide advanced capabilities for complex data processing scenarios.

    **When to use Model YAML:**
    - **Partitions** - Optimize performance with data partitioning strategies
    - **Incremental models** - Process only new or changed data efficiently
    - **Pre/post execution hooks** - Run custom logic before or after model execution
    - **Staging** - Create intermediate tables for complex transformations
    - **Output configuration** - Define specific output formats and destinations

    Model YAML files give you fine-grained control over how your data is processed and transformed, making them ideal for production workloads and complex analytics pipelines.

    :::

  
  
allOf:
  - title: Properties
    type: object
    properties:
      type:
        type: string
        const: model
        description: Refers to the resource type and must be `model`
      refresh:
        $ref: '#/definitions/schedule_properties'
        description: Specifies the refresh schedule that Rill should follow to re-ingest and update the underlying model data 
      connector:
        type: string
        const: connector
        description: Refers to the resource type and must be `connector`
      driver:
        type: string
        description: The type of connector, see [available connectors](../yaml/connectors#available-connector-types) (required)
      sql:
        type: string
        description: Raw SQL query to run against source
      timeout:
        type: string
        description: The maximum time to wait for model ingestion
      incremental:
        type: boolean
        description: whether incremental modeling is required (optional)
      change_mode:
        type: string
        enum:
          - reset
          - manual
          - patch
        description: Configure how changes to the model specifications are applied (optional). 'reset' will drop and recreate the model automatically, 'manual' will require a manual full or incremental refresh to apply changes, and 'patch' will switch to the new logic without re-processing historical data (only applies for incremental models).
      state:
        $ref: '#/definitions/data_properties'
        description: Refers to the explicitly defined state of your model, cannot be used with partitions (optional)
      partitions:
        $ref: '#/definitions/data_properties'
        description: Refers to the how your data is partitioned, cannot be used with state. (optional)
      materialize:
        type: boolean
        description: models will be materialized in olap
      partitions_watermark:
        type: string
        description: Refers to a customizable timestamp that can be set to check if an object has been updated (optional).
      partitions_concurrency:
        type: integer
        description: Refers to the number of concurrent partitions that can be read at the same time (optional).
      stage:
        type: object
        properties:
          connector:
            type: string
            description: Refers to the connector type for the staging table
        required:
          - connector
        description: in the case of staging models, where an input source does not support direct write to the output and a staging table is required
        additionalProperties: true
      output:
        type: object
        description: to define the properties of output
        properties:
          table:
            type: string
            description: Name of the output table. If not specified, the model name is used.
          materialize:
            type: boolean
            description: Whether to materialize the model as a table or view
          connector:
            type: string
            description: Refers to the connector type for the output table. Can be `clickhouse` or `duckdb` and their named connector 
          incremental_strategy:
            type: string
            enum:
              - append
              - merge
              - partition_overwrite
            description: Strategy to use for incremental updates. Can be 'append', 'merge' or 'partition_overwrite'
          unique_key:
            type: array
            items:
              type: string
            description: List of columns that uniquely identify a row for merge strategy
          partition_by:
            type: string
            description: Column or expression to partition the table by
        allOf:
          - if:
              title: Additional properties for `output` when `connector` is `clickhouse`
              properties:
                connector:
                  const: clickhouse
              required:
                - connector
            then:
              properties:
                type:
                  type: string
                  description: Type to materialize the model into. Can be 'TABLE', 'VIEW' or 'DICTIONARY'
                  enum:
                    - TABLE
                    - VIEW
                    - DICTIONARY
                columns:
                  type: string
                  description: Column names and types. Can also include indexes. If unspecified, detected from the query.
                engine_full:
                  type: string
                  description: Full engine definition in SQL format. Can include partition keys, order, TTL, etc.
                engine:
                  type: string
                  description: Table engine to use. Default is MergeTree
                order_by:
                  type: string
                  description: ORDER BY clause.
                partition_by:
                  type: string
                  description: Partition BY clause.
                primary_key:
                  type: string
                  description: PRIMARY KEY clause.
                sample_by:
                  type: string
                  description: SAMPLE BY clause.
                ttl:
                  type: string
                  description: TTL settings for the table or columns.
                table_settings:
                  type: string
                  description: Table-specific settings.
                query_settings:
                  type: string
                  description: Settings used in insert/create table as select queries.
                distributed_settings:
                  type: string
                  description: Settings for distributed table.
                distributed_sharding_key:
                  type: string
                  description: Sharding key for distributed table.
                dictionary_source_user:
                  type: string
                  description: User for accessing the source dictionary table (used if type is DICTIONARY).
                dictionary_source_password:
                  type: string
                  description: Password for the dictionary source user.
    required:
      - type
      - sql
  - $ref: '#/definitions/common_properties'
  - type: object
    allOf:
      - if:
          title: Additional properties when `connector` is [`athena`](./connectors#athena)
          properties:
            connector:
              const: athena
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/athena'
      - if:
          title: Additional properties when `connector` is [`azure`](./connectors#azure)
          properties:
            connector:
              const: azure
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/azure'
      - if:
          title: Additional properties when `connector` is [`bigquery`](./connectors#bigquery)
          properties:
            connector:
              const: bigquery
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/bigquery'
      - if:
          title: Additional properties when `connector` is [`duckdb`](./connectors#duckdb)
          properties:
            connector:
              const: duckdb
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/duckdb'
      - if:
          title: Additional properties when `connector` is [`gcs`](./connectors#gcs)
          properties:
            connector:
              const: gcs
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/gcs'
      - if:
          title: Additional properties when `connector` is [`redshift`](./connectors#redshift)
          properties:
            connector:
              const: redshift
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/redshift'
      - if:
          title: Additional properties when `connector` is [`s3`](./connectors#s3)
          properties:
            connector:
              const: s3
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/s3'
      - if:
          title: Additional properties when `connector` is [`salesforce`](./connectors#salesforce)
          properties:
            connector:
              const: salesforce
          required:
            - connector
        then:
          $ref: '#/definitions/model/definitions/salesforce'
definitions:
  schedule_properties:
    type: object
    properties:
      cron:
        type: string
        description: A cron expression that defines the execution schedule
      time_zone:
        type: string
        description: Time zone to interpret the schedule in (e.g., 'UTC', 'America/Los_Angeles').
      disable:
        type: boolean
        description: 'If true, disables the resource without deleting it.'
      ref_update:
        type: boolean
        description: 'If true, allows the resource to run when a dependency updates.'
      run_in_dev:
        type: boolean
        description: 'If true, allows the schedule to run in development mode.'
  data_properties:
    oneOf:
      - title: SQL Query
        type: object
        description: Executes a raw SQL query against the project's data models.
        properties:
          sql:
            type: string
            description: Raw SQL query to run against existing models in the project.
          connector:
            type: string
            description: specifies the connector to use when running SQL or glob queries.
        required:
          - sql
      - title: Metrics View Query
        type: object
        description: Executes a SQL query that targets a defined metrics view.
        properties:
          metrics_sql:
            type: string
            description: SQL query that targets a metrics view in the project
        required:
          - metrics_sql
      - title: Custom API Call
        type: object
        description: Calls a custom API defined in the project to compute data.
        properties:
          api:
            type: string
            description: Name of a custom API defined in the project.
          args:
            type: object
            description: Arguments to pass to the custom API.
            additionalProperties: true
        required:
          - api
      - title: File Glob Query
        type: object
        description: Uses a file-matching pattern (glob) to query data from a connector.
        properties:
          glob:
            description:  Defines the file path or pattern to query from the specified connector.
            anyOf:
              - type: string
                description: A simple file path/glob pattern as a string.
              - type: object
                description: An object-based configuration for specifying a file path/glob pattern with advanced options.
                additionalProperties: true
          connector:
            type: string
            description: Specifies the connector to use with the glob input.
        required:
          - glob
      - title: Resource Status Check
        type: object
        description: Uses the status of a resource as data.
        properties:
          resource_status:
            type: object
            description: Based on resource status
            properties:
              where_error:
                type: boolean
                description: Indicates whether the condition should trigger when the resource is in an error state.
            additionalProperties: true
        required:
          - resource_status
  common_properties:
    type: object
    title: "Common Properties"
    properties:
      name:
        type: string
        description: Name is usually inferred from the filename, but can be specified manually.
      refs:
        type: array
        description: 'List of resource references'
        items:
          type: string
          description: A string reference like `<resource-name>` or `<type/resource-name>`.
      dev:
        type: object
        description: Overrides any properties in development environment.
      prod:
        type: object
        description: Overrides any properties in production environment.
  model:
    definitions:
      athena:
        type: object
        properties:
          output_location:
            type: string
            description: Output location for query results in S3.
          workgroup:
            type: string
            description: AWS Athena workgroup to use for queries.
          region:
            type: string
            description: AWS region to connect to Athena and the output location.
      azure:
        type: object
        properties:
          path:
            type: string
            description: Path to the source
          account:
            type: string
            description: Account identifier
          uri:
            type: string
            description: Source URI
          extract:
            type: object
            description: Arbitrary key-value pairs for extraction settings
            additionalProperties: true
          glob:
            type: object
            description: Settings related to glob file matching.
            properties:
              max_total_size:
                type: integer
                description: Maximum total size (in bytes) matched by glob
              max_objects_matched:
                type: integer
                description: Maximum number of objects matched by glob
              max_objects_listed:
                type: integer
                description: Maximum number of objects listed in glob
              page_size:
                type: integer
                description: Page size for glob listing
          batch_size:
            type: string
            description: 'Size of a batch (e.g., ''100MB'')'
      bigquery:
        type: object
        properties:
          project_id:
            type: string
            description: ID of the BigQuery project.
      duckdb:
        type: object
        properties:
          path:
            type: string
            description: Path to the data source.
          format:
            type: string
            description: 'Format of the data source (e.g., csv, json, parquet).'
          pre_exec:
            type: string
            description: 'refers to SQL queries to run before the main query, available for DuckDB-based models. _(optional)_. Ensure `pre_exec` queries are idempotent. Use `IF NOT EXISTS` statements when applicable.'
          post_exec:
            type: string
            description: 'refers to a SQL query that is run after the main query, available for DuckDB-based models. _(optional)_. Ensure `post_exec` queries are idempotent. Use `IF EXISTS` statements when applicable.'
            examples:
            - pre_exec: ATTACH IF NOT EXISTS 'dbname=postgres host=localhost port=5432 user=postgres password=postgres' AS postgres_db (TYPE POSTGRES);
              sql: SELECT * FROM postgres_query('postgres_db', 'SELECT * FROM USERS')
              post_exec: DETACH DATABASE IF EXISTS postgres_db 
      gcs:
        type: object
        properties:
          path:
            type: string
            description: Path to the source
          uri:
            type: string
            description: Source URI
          extract:
            type: object
            description: key-value pairs for extraction settings
            additionalProperties: true
          glob:
            type: object
            description: Settings related to glob file matching.
            properties:
              max_total_size:
                type: integer
                description: Maximum total size (in bytes) matched by glob
              max_objects_matched:
                type: integer
                description: Maximum number of objects matched by glob
              max_objects_listed:
                type: integer
                description: Maximum number of objects listed in glob
              page_size:
                type: integer
                description: Page size for glob listing
          batch_size:
            type: string
            description: 'Size of a batch (e.g., ''100MB'')'
      local_file:
        type: object
        properties:
          path:
            type: string
            description: Path to the data source.
          format:
            type: string
            description: 'Format of the data source (e.g., csv, json, parquet).'
      redshift:
        type: object
        properties:
          output_location:
            type: string
            description: S3 location where query results are stored.
          workgroup:
            type: string
            description: Redshift Serverless workgroup to use.
          database:
            type: string
            description: Name of the Redshift database.
          cluster_identifier:
            type: string
            description: Identifier of the Redshift cluster.
          role_arn:
            type: string
            description: ARN of the IAM role to assume for Redshift access.
          region:
            type: string
            description: AWS region of the Redshift deployment.
      s3:
        type: object
        properties:
          region:
            type: string
            description: AWS region
          endpoint:
            type: string
            description: AWS Endpoint
          path:
            type: string
            description: Path to the source
          uri:
            type: string
            description: Source URI
          extract:
            type: object
            description: key-value pairs for extraction settings
            additionalProperties: true
          glob:
            type: object
            description: Settings related to glob file matching.
            properties:
              max_total_size:
                type: integer
                description: Maximum total size (in bytes) matched by glob
              max_objects_matched:
                type: integer
                description: Maximum number of objects matched by glob
              max_objects_listed:
                type: integer
                description: Maximum number of objects listed in glob
              page_size:
                type: integer
                description: Page size for glob listing
          batch_size:
            type: string
            description: 'Size of a batch (e.g., ''100MB'')'
      salesforce:
        type: object
        properties:
          soql:
            type: string
            description: SOQL query to execute against the Salesforce instance.
          sobject:
            type: string
            description: Salesforce object (e.g., Account, Contact) targeted by the query.
          queryAll:
            type: boolean
            description: Whether to include deleted and archived records in the query (uses queryAll API). 